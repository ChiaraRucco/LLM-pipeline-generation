{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1137619-5355-4fef-890f-52fe0a9dd7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PROMPT\n",
    "Generate a pipeline for databricks that takes data from an API (https://api.spacexdata.com/v3/launches), performs a basic transformation task, and posts the result to another API (https://httpbin.org/post). Add prints for debugging the activities and display the execution time of the entire cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "605a440b-4230-4d2a-ba1b-ff7c456b33d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Start timing the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Step 1: Fetch data from the SpaceX API\n",
    "def fetch_spacex_data():\n",
    "    url = \"https://api.spacexdata.com/v3/launches\"\n",
    "    try:\n",
    "        print(\"Fetching data from SpaceX API...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "        print(\"Data fetched successfully.\")\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from SpaceX API: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 2: Perform a basic transformation using PySpark\n",
    "def transform_data(data):\n",
    "    print(\"Transforming data...\")\n",
    "    # Convert the JSON data into a Spark DataFrame\n",
    "    spark = SparkSession.builder.appName(\"SpaceXTransformation\").getOrCreate()\n",
    "    df = spark.createDataFrame(data)\n",
    "    \n",
    "    # Example transformation: Filter launches where the rocket name contains \"Falcon\"\n",
    "    filtered_df = df.filter(col(\"rocket.rocket_name\").like(\"%Falcon%\"))\n",
    "    \n",
    "    # Select specific columns for simplicity\n",
    "    transformed_df = filtered_df.select(\n",
    "        col(\"flight_number\"),\n",
    "        col(\"mission_name\"),\n",
    "        col(\"launch_year\"),\n",
    "        col(\"rocket.rocket_name\").alias(\"rocket_name\")\n",
    "    )\n",
    "    \n",
    "    print(\"Transformation completed.\")\n",
    "    return transformed_df.toPandas().to_dict(orient=\"records\")  # Convert back to JSON for posting\n",
    "\n",
    "# Step 3: Post the transformed data to the target API\n",
    "def post_data_to_api(transformed_data):\n",
    "    url = \"https://httpbin.org/post\"\n",
    "    try:\n",
    "        print(\"Posting transformed data to target API...\")\n",
    "        response = requests.post(url, json=transformed_data)\n",
    "        response.raise_for_status()\n",
    "        print(\"Data posted successfully.\")\n",
    "        print(\"Response from target API:\", response.json())\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error posting data to target API: {e}\")\n",
    "        raise\n",
    "\n",
    "# Main pipeline execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Fetch data from SpaceX API\n",
    "        spacex_data = fetch_spacex_data()\n",
    "        \n",
    "        # Transform the fetched data\n",
    "        transformed_data = transform_data(spacex_data)\n",
    "        \n",
    "        # Post the transformed data to the target API\n",
    "        post_data_to_api(transformed_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline failed with error: {e}\")\n",
    "    \n",
    "    # Calculate and display the total execution time\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Pipeline executed in {execution_time:.2f} seconds.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b437afd-1e97-4b88-954a-f25c96299076",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "after the error:\n",
    "Fetching data from SpaceX API...\n",
    "Data fetched successfully.\n",
    "Transforming data...\n",
    "Pipeline failed with error: [CANNOT_INFER_TYPE_FOR_FIELD] Unable to infer the type of the field `links`.\n",
    "Pipeline executed in 0.92 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00a6e005-6dd3-4f97-b309-f951f9082179",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Start timing the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Step 1: Fetch data from the SpaceX API\n",
    "def fetch_spacex_data():\n",
    "    url = \"https://api.spacexdata.com/v3/launches\"\n",
    "    try:\n",
    "        print(\"Fetching data from SpaceX API...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "        print(\"Data fetched successfully.\")\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from SpaceX API: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 2: Perform a basic transformation using PySpark\n",
    "def transform_data(data):\n",
    "    print(\"Transforming data...\")\n",
    "    # Convert the JSON data into a Spark DataFrame with a simplified schema\n",
    "    spark = SparkSession.builder.appName(\"SpaceXTransformation\").getOrCreate()\n",
    "    \n",
    "    # Flatten the nested structure by selecting specific fields\n",
    "    flattened_data = [\n",
    "        {\n",
    "            \"flight_number\": item[\"flight_number\"],\n",
    "            \"mission_name\": item[\"mission_name\"],\n",
    "            \"launch_year\": item[\"launch_year\"],\n",
    "            \"rocket_name\": item[\"rocket\"][\"rocket_name\"],\n",
    "            \"video_link\": item[\"links\"].get(\"video_link\", None)  # Handle nested links field\n",
    "        }\n",
    "        for item in data\n",
    "    ]\n",
    "    \n",
    "    df = spark.createDataFrame(flattened_data)\n",
    "    \n",
    "    # Example transformation: Filter launches where the rocket name contains \"Falcon\"\n",
    "    filtered_df = df.filter(col(\"rocket_name\").like(\"%Falcon%\"))\n",
    "    \n",
    "    print(\"Transformation completed.\")\n",
    "    return filtered_df.toPandas().to_dict(orient=\"records\")  # Convert back to JSON for posting\n",
    "\n",
    "# Step 3: Post the transformed data to the target API\n",
    "def post_data_to_api(transformed_data):\n",
    "    url = \"https://httpbin.org/post\"\n",
    "    try:\n",
    "        print(\"Posting transformed data to target API...\")\n",
    "        response = requests.post(url, json=transformed_data)\n",
    "        response.raise_for_status()\n",
    "        print(\"Data posted successfully.\")\n",
    "        print(\"Response from target API:\", response.json())\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error posting data to target API: {e}\")\n",
    "        raise\n",
    "\n",
    "# Main pipeline execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Fetch data from SpaceX API\n",
    "        spacex_data = fetch_spacex_data()\n",
    "        \n",
    "        # Transform the fetched data\n",
    "        transformed_data = transform_data(spacex_data)\n",
    "        \n",
    "        # Post the transformed data to the target API\n",
    "        post_data_to_api(transformed_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline failed with error: {e}\")\n",
    "    \n",
    "    # Calculate and display the total execution time\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Pipeline executed in {execution_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8881c113-1393-4b63-9297-3d530f91b32f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ETL QWEN",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
