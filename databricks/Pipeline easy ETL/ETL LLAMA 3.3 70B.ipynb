{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1137619-5355-4fef-890f-52fe0a9dd7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PROMPT\n",
    "Generate a pipeline for databricks that takes data from an API (https://api.spacexdata.com/v3/launches), performs a basic transformation task, and posts the result to another API (https://httpbin.org/post). Add prints for debugging the activities and display the execution time of the entire cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8881c113-1393-4b63-9297-3d530f91b32f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SpaceX Pipeline\").getOrCreate()\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fetch data from SpaceX API\n",
    "print(\"Fetching data from SpaceX API...\")\n",
    "response = requests.get('https://api.spacexdata.com/v3/launches')\n",
    "print(\"Data fetched successfully.\")\n",
    "\n",
    "# Parse JSON response\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# Create a Spark DataFrame from the data\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "# Perform basic transformation task (e.g., convert launch date to timestamp)\n",
    "from pyspark.sql.functions import col\n",
    "df_transformed = df.withColumn(\"launch_date\", col(\"launch_date_unix\").cast(\"timestamp\"))\n",
    "\n",
    "# Print transformed data for debugging\n",
    "print(\"Transformed Data:\")\n",
    "df_transformed.show()\n",
    "\n",
    "# Post transformed data to httpbin.org\n",
    "print(\"Posting data to httpbin.org...\")\n",
    "response = requests.post('https://httpbin.org/post', json=df_transformed.toPandas().to_dict(orient='records'))\n",
    "print(\"Data posted successfully.\")\n",
    "\n",
    "# Print response from httpbin.org for debugging\n",
    "print(\"Response from httpbin.org:\")\n",
    "print(response.text)\n",
    "\n",
    "# Stop timer and print execution time\n",
    "end_time = time.time()\n",
    "print(\"Execution time: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e8b7666-1ba7-4ae1-b2a1-e21e8ea34b85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I send to LLAMA the output cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1fca1f5-6829-46d1-ad88-730e9ae8ab9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType, DoubleType, ArrayType, MapType\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SpaceX Pipeline\").getOrCreate()\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fetch data from SpaceX API\n",
    "print(\"Fetching data from SpaceX API...\")\n",
    "response = requests.get('https://api.spacexdata.com/v3/launches')\n",
    "print(\"Data fetched successfully.\")\n",
    "\n",
    "# Parse JSON response\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# Define custom schema\n",
    "schema = StructType([\n",
    "    StructField(\"flight_number\", IntegerType(), True),\n",
    "    StructField(\"mission_name\", StringType(), True),\n",
    "    StructField(\"mission_id\", ArrayType(StringType()), True),\n",
    "    StructField(\"launch_year\", StringType(), True),\n",
    "    StructField(\"launch_date_unix\", LongType(), True),\n",
    "    StructField(\"launch_date_utc\", StringType(), True),\n",
    "    StructField(\"launch_window\", LongType(), True),\n",
    "    StructField(\"rocket\", StructType([\n",
    "        StructField(\"rocket_id\", StringType(), True),\n",
    "        StructField(\"rocket_name\", StringType(), True),\n",
    "        StructField(\"rocket_type\", StringType(), True),\n",
    "        StructField(\"first_stage\", StructType([\n",
    "            StructField(\"cores\", ArrayType(StructType([\n",
    "                StructField(\"core_serial\", StringType(), True),\n",
    "                StructField(\"flight\", IntegerType(), True),\n",
    "                StructField(\"block\", IntegerType(), True),\n",
    "                StructField(\"gridfins\", BooleanType(), True),\n",
    "                StructField(\"legs\", BooleanType(), True),\n",
    "                StructField(\"reused\", BooleanType(), True),\n",
    "                StructField(\"land_success\", BooleanType(), True),\n",
    "                StructField(\"landing_intent\", BooleanType(), True),\n",
    "                StructField(\"landing_type\", StringType(), True),\n",
    "                StructField(\"recovery_attempt\", BooleanType(), True),\n",
    "                StructField(\"recovery_ship\", StructType([\n",
    "                    StructField(\"name\", StringType(), True),\n",
    "                    StructField(\"home_port\", StringType(), True)\n",
    "                ]), True)\n",
    "            ])), True),\n",
    "            StructField(\"cores\", ArrayType(StructType([\n",
    "                StructField(\"core_serial\", StringType(), True),\n",
    "                StructField(\"flight\", IntegerType(), True),\n",
    "                StructField(\"block\", IntegerType(), True),\n",
    "                StructField(\"gridfins\", BooleanType(), True),\n",
    "                StructField(\"legs\", BooleanType(), True),\n",
    "                StructField(\"reused\", BooleanType(), True),\n",
    "                StructField(\"land_success\", BooleanType(), True),\n",
    "                StructField(\"landing_intent\", BooleanType(), True),\n",
    "                StructField(\"landing_type\", StringType(), True),\n",
    "                StructField(\"recovery_attempt\", BooleanType(), True),\n",
    "                StructField(\"recovery_ship\", StructType([\n",
    "                    StructField(\"name\", StringType(), True),\n",
    "                    StructField(\"home_port\", StringType(), True)\n",
    "                ]), True)\n",
    "            ])), True)\n",
    "        ])), True),\n",
    "        StructField(\"second_stage\", StructType([\n",
    "            StructField(\"block\", IntegerType(), True),\n",
    "            StructField(\"payloads\", ArrayType(StructType([\n",
    "                StructField(\"payload_id\", StringType(), True),\n",
    "                StructField(\"norad_id\", ArrayType(StringType()), True),\n",
    "                StructField(\"reused\", BooleanType(), True),\n",
    "                StructField(\"customers\", ArrayType(StringType()), True),\n",
    "                StructField(\"nationality\", StringType(), True),\n",
    "                StructField(\"launch_mass_kg\", DoubleType(), True),\n",
    "                StructField(\"launch_mass_lbs\", DoubleType(), True),\n",
    "                StructField(\"orbit\", StringType(), True),\n",
    "                StructField(\"reference_system\", StringType(), True),\n",
    "                StructField(\"regime\", StringType(), True),\n",
    "                StructField(\"longitude\", DoubleType(), True),\n",
    "                StructField(\"semi_major_axis_km\", DoubleType(), True),\n",
    "                StructField(\"eccentricity\", DoubleType(), True),\n",
    "                StructField(\"periapsis_km\", DoubleType(), True),\n",
    "                StructField(\"apoapsis_km\", DoubleType(), True),\n",
    "                StructField(\"inclination_deg\", DoubleType(), True),\n",
    "                StructField(\"period_min\", DoubleType(), True),\n",
    "                StructField(\"lifespan_years\", DoubleType(), True),\n",
    "                StructField(\"epoch\", StringType(), True),\n",
    "                StructField(\"mean_motion\", DoubleType(), True),\n",
    "                StructField(\"raan\", DoubleType(), True),\n",
    "                StructField(\"arg_of_pericenter\", DoubleType(), True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "012d7b8a-2fb6-4473-b29a-3279d9919bbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "i try again to put the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e81f5e3f-e1ee-4477-af95-2dd5cdacb508",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SpaceX Pipeline\").getOrCreate()\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fetch data from SpaceX API\n",
    "print(\"Fetching data from SpaceX API...\")\n",
    "response = requests.get('https://api.spacexdata.com/v3/launches')\n",
    "print(\"Data fetched successfully.\")\n",
    "\n",
    "# Parse JSON response\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# Create a Spark DataFrame from the data\n",
    "df = spark.createDataFrame(data)\n",
    "\n",
    "# Print schema for debugging\n",
    "print(\"Schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Perform basic transformation task (e.g., convert launch date to timestamp)\n",
    "from pyspark.sql.functions import col\n",
    "df_transformed = df.withColumn(\"launch_date\", col(\"launch_date_unix\").cast(\"timestamp\"))\n",
    "\n",
    "# Print transformed data for debugging\n",
    "print(\"Transformed Data:\")\n",
    "df_transformed.show()\n",
    "\n",
    "# Post transformed data to httpbin.org\n",
    "print(\"Posting data to httpbin.org...\")\n",
    "response = requests.post('https://httpbin.org/post', json=df_transformed.toPandas().to_dict(orient='records'))\n",
    "print(\"Data posted successfully.\")\n",
    "\n",
    "# Print response from httpbin.org for debugging\n",
    "print(\"Response from httpbin.org:\")\n",
    "print(response.text)\n",
    "\n",
    "# Stop timer and print execution time\n",
    "end_time = time.time()\n",
    "print(\"Execution time: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca7229bc-f125-4f9b-965b-ba3d36ff378d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dca19d22-6bc7-41c9-846b-e4e658d0d338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SpaceX Pipeline\").getOrCreate()\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fetch data from SpaceX API\n",
    "print(\"Fetching data from SpaceX API...\")\n",
    "response = requests.get('https://api.spacexdata.com/v3/launches')\n",
    "print(\"Data fetched successfully.\")\n",
    "\n",
    "# Parse JSON response\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# Create a Pandas DataFrame from the data\n",
    "pdf = pd.DataFrame(data)\n",
    "\n",
    "# Create a PySpark DataFrame from the Pandas DataFrame\n",
    "df = spark.createDataFrame(pdf)\n",
    "\n",
    "# Print schema for debugging\n",
    "print(\"Schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Perform basic transformation task (e.g., convert launch date to timestamp)\n",
    "from pyspark.sql.functions import col\n",
    "df_transformed = df.withColumn(\"launch_date\", col(\"launch_date_unix\").cast(\"timestamp\"))\n",
    "\n",
    "# Print transformed data for debugging\n",
    "print(\"Transformed Data:\")\n",
    "df_transformed.show()\n",
    "\n",
    "# Post transformed data to httpbin.org\n",
    "print(\"Posting data to httpbin.org...\")\n",
    "response = requests.post('https://httpbin.org/post', json=df_transformed.toPandas().to_dict(orient='records'))\n",
    "print(\"Data posted successfully.\")\n",
    "\n",
    "# Print response from httpbin.org for debugging\n",
    "print(\"Response from httpbin.org:\")\n",
    "print(response.text)\n",
    "\n",
    "# Stop timer and print execution time\n",
    "end_time = time.time()\n",
    "print(\"Execution time: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22814611-356f-48cc-9fa1-a13f38e44e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here the code try to transform but can't perform the posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f41f87f-c9a7-48da-acc6-2bf500725122",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SpaceX Pipeline\").getOrCreate()\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fetch data from SpaceX API\n",
    "print(\"Fetching data from SpaceX API...\")\n",
    "response = requests.get('https://api.spacexdata.com/v3/launches')\n",
    "print(\"Data fetched successfully.\")\n",
    "\n",
    "# Parse JSON response\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# Create a Pandas DataFrame from the data\n",
    "pdf = pd.DataFrame(data)\n",
    "\n",
    "# Create a PySpark DataFrame from the Pandas DataFrame\n",
    "df = spark.createDataFrame(pdf)\n",
    "\n",
    "# Print schema for debugging\n",
    "print(\"Schema:\")\n",
    "df.printSchema()\n",
    "\n",
    "# Perform basic transformation task (e.g., convert launch date to timestamp)\n",
    "from pyspark.sql.functions import col\n",
    "df_transformed = df.withColumn(\"launch_date\", col(\"launch_date_unix\").cast(\"timestamp\"))\n",
    "\n",
    "# Print transformed data for debugging\n",
    "print(\"Transformed Data:\")\n",
    "df_transformed.show()\n",
    "\n",
    "# Post transformed data to httpbin.org\n",
    "print(\"Posting data to httpbin.org...\")\n",
    "data_to_post = df_transformed.toPandas().to_dict(orient='records')\n",
    "for item in data_to_post:\n",
    "    for key, value in item.items():\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            item[key] = list(value)\n",
    "        elif isinstance(value, dict):\n",
    "            for k, v in value.items():\n",
    "                if isinstance(v, (list, tuple)):\n",
    "                    value[k] = list(v)\n",
    "response = requests.post('https://httpbin.org/post', json=data_to_post)\n",
    "print(\"Data posted successfully.\")\n",
    "\n",
    "# Print response from httpbin.org for debugging\n",
    "print(\"Response from httpbin.org:\")\n",
    "print(response.text)\n",
    "\n",
    "# Stop timer and print execution time\n",
    "end_time = time.time()\n",
    "print(\"Execution time: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b11760dd-d884-4a05-ada0-ca5044704947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "TRY AND CAN'T RESOLVE THESE ISSUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55cb0913-c273-4963-b018-d50ff97cd9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ETL LLAMA 3.3 70B",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
