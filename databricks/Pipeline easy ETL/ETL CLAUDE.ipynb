{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1137619-5355-4fef-890f-52fe0a9dd7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PROMPT\n",
    "Generate a pipeline for databricks that takes data from an API (https://api.spacexdata.com/v3/launches), performs a basic transformation task, and posts the result to another API (https://httpbin.org/post). Add prints for debugging the activities and display the execution time of the entire cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4db6680-8d1c-4578-8bd7-fadffc5669ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, expr, to_timestamp\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SpaceX API Pipeline\").getOrCreate()\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"Starting SpaceX API Pipeline\")\n",
    "    \n",
    "    # Step 1: Fetch data from SpaceX API\n",
    "    print(\"Fetching data from SpaceX API...\")\n",
    "    try:\n",
    "        response = requests.get(\"https://api.spacexdata.com/v3/launches\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"Successfully fetched {len(data)} launches from SpaceX API\")\n",
    "        else:\n",
    "            print(f\"Error fetching data: HTTP {response.status_code}\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during API fetch: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Convert JSON data to DataFrame\n",
    "    print(\"Converting JSON data to DataFrame...\")\n",
    "    try:\n",
    "        # Convert to pandas first\n",
    "        pdf = pd.DataFrame(data)\n",
    "        # Then convert to Spark DataFrame\n",
    "        df = spark.createDataFrame(pdf)\n",
    "        print(f\"Created DataFrame with schema: {df.schema.simpleString()}\")\n",
    "        print(f\"DataFrame has {df.count()} rows and {len(df.columns)} columns\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during DataFrame creation: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Step 3: Transform the data\n",
    "    print(\"Transforming data...\")\n",
    "    try:\n",
    "        # Select and transform relevant columns\n",
    "        transformed_df = df.select(\n",
    "            col(\"flight_number\"),\n",
    "            col(\"mission_name\"),\n",
    "            to_timestamp(col(\"launch_date_utc\")).alias(\"launch_date\"),\n",
    "            col(\"rocket.rocket_name\").alias(\"rocket_name\"),\n",
    "            col(\"launch_success\"),\n",
    "            col(\"details\")\n",
    "        )\n",
    "        \n",
    "        # Add a success_status column with descriptive values\n",
    "        transformed_df = transformed_df.withColumn(\n",
    "            \"success_status\",\n",
    "            expr(\"CASE WHEN launch_success = true THEN 'Successful' \" +\n",
    "                 \"WHEN launch_success = false THEN 'Failed' \" +\n",
    "                 \"ELSE 'Unknown' END\")\n",
    "        )\n",
    "        \n",
    "        print(\"Transformation complete\")\n",
    "        print(f\"Transformed DataFrame has {transformed_df.count()} rows and {len(transformed_df.columns)} columns\")\n",
    "        \n",
    "        # Show sample data\n",
    "        print(\"Sample of transformed data:\")\n",
    "        transformed_df.show(5, truncate=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Exception during transformation: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Step 4: Convert back to JSON for API post\n",
    "    print(\"Converting DataFrame to JSON...\")\n",
    "    try:\n",
    "        # Convert to pandas and then to JSON\n",
    "        transformed_json = transformed_df.toPandas().to_dict(orient='records')\n",
    "        print(f\"Created JSON with {len(transformed_json)} records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during JSON conversion: {str(e)}\")\n",
    "        return\n",
    "    \n",
    "    # Step 5: Post results to httpbin API\n",
    "    print(\"Posting results to httpbin.org...\")\n",
    "    try:\n",
    "        # Creating a summary object to post\n",
    "        summary_data = {\n",
    "            \"source\": \"SpaceX API\",\n",
    "            \"total_launches\": len(transformed_json),\n",
    "            \"successful_launches\": sum(1 for launch in transformed_json if launch[\"launch_success\"] == True),\n",
    "            \"failed_launches\": sum(1 for launch in transformed_json if launch[\"launch_success\"] == False),\n",
    "            \"data\": transformed_json[:5]  # Send only first 5 records as sample\n",
    "        }\n",
    "        \n",
    "        # Post to httpbin\n",
    "        post_response = requests.post(\n",
    "            \"https://httpbin.org/post\",\n",
    "            json=summary_data,\n",
    "            headers={\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        \n",
    "        if post_response.status_code == 200:\n",
    "            print(\"Successfully posted data to httpbin.org\")\n",
    "            print(\"Response from httpbin:\")\n",
    "            print(json.dumps(post_response.json(), indent=2)[:500] + \"...\")  # Print truncated response\n",
    "        else:\n",
    "            print(f\"Error posting data: HTTP {post_response.status_code}\")\n",
    "            print(post_response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during API post: {str(e)}\")\n",
    "    \n",
    "    # Calculate and display execution time\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Pipeline execution completed in {execution_time:.2f} seconds\")\n",
    "\n",
    "# Execute pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d94418ec-778f-42d1-a7de-38abc66fc65d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ETL CLAUDE",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
