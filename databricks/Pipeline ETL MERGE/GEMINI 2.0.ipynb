{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6013620-52de-4e21-aa7c-ea5c0d9a24a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are an expert Python developer specializing in the Databricks environment. Your task is to create a complete Python script to be executed within a Databricks notebook. The script must perform the following operations:\n",
    "1.\tData Retrieval from SpaceX API:\n",
    "o\tInteract with the SpaceX v3 REST API (https://api.spacexdata.com/v3).\n",
    "o\tRetrieve data from two specific endpoints: \n",
    "\tAll launches: https://api.spacexdata.com/v3/launches\n",
    "\tAll rockets: https://api.spacexdata.com/v3/rockets\n",
    "o\tHandle potential errors during the API calls (e.g., timeouts, non-200 status codes).\n",
    "2.\tMerge Operation:\n",
    "o\tPerform a \"merge\" (or join) operation between the launches data and the rockets data.\n",
    "o\tMerge Logic: For each launch record, add the rocket's name (rocket_name) from the rockets dataset. The match should be based on the rocket.rocket_id field present in each launch record corresponding to the rocket_id field in each rocket record.\n",
    "o\tThe final result should be a list of dictionaries, where each dictionary represents a launch enriched with its corresponding rocket name.\n",
    "3.\tControl Parameters and Debugging:\n",
    "o\tInclude variables at the beginning of the script to define the API endpoint URLs, making them easily modifiable.\n",
    "o\tUse Python's standard logging module to provide informative output during execution. Configure logging to display messages at the INFO level.\n",
    "o\tLog key messages such as: starting data retrieval, number of launches retrieved, number of rockets retrieved, starting merge operation, number of records after merge, starting upload to httpbin, upload outcome.\n",
    "4.\tExecution Time Measurement:\n",
    "o\tCode Execution Time: Measure the time taken to perform the main operations (data retrieval + merge). Print this time after the merge operation is complete.\n",
    "o\tPipeline Execution Time: Measure the total execution time of the entire script (from the beginning until after the upload to httpbin). Print this total time at the end of the script. Use Python's time module.\n",
    "5.\tUpload Result:\n",
    "o\tTake the resulting list from the merge operation.\n",
    "o\tSerialize it into JSON format.\n",
    "o\tMake an HTTP POST request to the https://httpbin.org/post endpoint, sending the resulting JSON data in the request body.\n",
    "o\tVerify the response from httpbin.org (e.g., check the status code) and log the outcome of the upload operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acadff3a-4609-4a37-a316-cd5989c71be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define API endpoint URLs\n",
    "LAUNCHES_API_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "ROCKETS_API_URL = \"https://api.spacexdata.com/v3/rockets\"\n",
    "HTTPBIN_POST_URL = \"https://httpbin.org/post\"\n",
    "\n",
    "def fetch_data_from_api(url):\n",
    "    \"\"\"\n",
    "    Fetches data from a given API endpoint.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the API endpoint.\n",
    "\n",
    "    Returns:\n",
    "        list or None: A list of dictionaries containing the API response data,\n",
    "                     or None if an error occurred.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Fetching data from: {url}\")\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error fetching data from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def merge_launches_and_rockets(launches, rockets):\n",
    "    \"\"\"\n",
    "    Merges launch data with rocket names based on rocket IDs.\n",
    "\n",
    "    Args:\n",
    "        launches (list): A list of launch dictionaries.\n",
    "        rockets (list): A list of rocket dictionaries.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of launch dictionaries enriched with the 'rocket_name'.\n",
    "    \"\"\"\n",
    "    if not launches or not rockets:\n",
    "        logging.warning(\"No launches or rockets data available for merging.\")\n",
    "        return []\n",
    "\n",
    "    rockets_map = {rocket['rocket_id']: rocket['rocket_name'] for rocket in rockets}\n",
    "    merged_data = []\n",
    "    for launch in launches:\n",
    "        rocket_id = launch.get('rocket', {}).get('rocket_id')\n",
    "        if rocket_id and rocket_id in rockets_map:\n",
    "            launch['rocket_name'] = rockets_map[rocket_id]\n",
    "            merged_data.append(launch)\n",
    "        else:\n",
    "            logging.warning(f\"Could not find rocket name for launch with ID: {launch.get('flight_number')}\")\n",
    "            # Optionally, you could still include the launch without the rocket name\n",
    "            # launch['rocket_name'] = None\n",
    "            # merged_data.append(launch)\n",
    "    return merged_data\n",
    "\n",
    "def upload_data_to_httpbin(data):\n",
    "    \"\"\"\n",
    "    Uploads data to the httpbin.org/post endpoint as JSON.\n",
    "\n",
    "    Args:\n",
    "        data (list): The data to be uploaded.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the upload was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Uploading data to: {HTTPBIN_POST_URL}\")\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        json_data = json.dumps(data)\n",
    "        response = requests.post(HTTPBIN_POST_URL, headers=headers, data=json_data, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        logging.info(f\"Upload to httpbin successful. Status code: {response.status_code}\")\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error uploading data to httpbin: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    logging.info(\"Starting data retrieval from SpaceX API.\")\n",
    "    start_time = time.time()\n",
    "    launches_data = fetch_data_from_api(LAUNCHES_API_URL)\n",
    "    rockets_data = fetch_data_from_api(ROCKETS_API_URL)\n",
    "    end_time = time.time()\n",
    "    retrieval_time = end_time - start_time\n",
    "\n",
    "    if launches_data:\n",
    "        logging.info(f\"Retrieved {len(launches_data)} launch records.\")\n",
    "    else:\n",
    "        logging.warning(\"Failed to retrieve launch data.\")\n",
    "\n",
    "    if rockets_data:\n",
    "        logging.info(f\"Retrieved {len(rockets_data)} rocket records.\")\n",
    "    else:\n",
    "        logging.warning(\"Failed to retrieve rocket data.\")\n",
    "\n",
    "    if launches_data and rockets_data:\n",
    "        logging.info(\"Starting merge operation.\")\n",
    "        start_time = time.time()\n",
    "        merged_data = merge_launches_and_rockets(launches_data, rockets_data)\n",
    "        end_time = time.time()\n",
    "        merge_time = end_time - start_time\n",
    "        logging.info(f\"Merge operation completed. Number of records after merge: {len(merged_data)}.\")\n",
    "        logging.info(f\"Time taken for data retrieval and merge: {retrieval_time + merge_time:.2f} seconds.\")\n",
    "\n",
    "        logging.info(\"Starting upload to httpbin.\")\n",
    "        upload_successful = upload_data_to_httpbin(merged_data)\n",
    "        if upload_successful:\n",
    "            logging.info(\"Upload to httpbin was successful.\")\n",
    "        else:\n",
    "            logging.error(\"Upload to httpbin failed.\")\n",
    "    else:\n",
    "        logging.warning(\"Skipping merge and upload due to missing data.\")\n",
    "\n",
    "    total_end_time = time.time()\n",
    "    total_execution_time = total_end_time - total_start_time\n",
    "    logging.info(f\"Total execution time of the script: {total_execution_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cd61cbe-c2c1-4973-84e9-6e0224f7c03e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GEMINI 2.0",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
