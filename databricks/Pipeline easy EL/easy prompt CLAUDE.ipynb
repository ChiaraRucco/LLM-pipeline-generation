{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f139fb76-a5a2-4df0-ae31-21efd44ab14d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##**PROMPT**\n",
    "Generate a pipeline in Databricks that: 1 Performs a GET request to space x launches API  2 POST the result to httpbin.org 3 includes error and time evaluation in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcf29b37-5fc8-4d56-a47a-73b1d5d55b3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook\n",
    "# Title: SpaceX API Data Pipeline with Error Handling and Timing\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, DoubleType\n",
    "import logging\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"SpaceX API Pipeline\").getOrCreate()\n",
    "\n",
    "# Define schema for metrics tracking\n",
    "metrics_schema = StructType([\n",
    "  StructField(\"timestamp\", TimestampType(), False),\n",
    "  StructField(\"operation\", StringType(), False),\n",
    "  StructField(\"status\", StringType(), False),\n",
    "  StructField(\"duration_seconds\", DoubleType(), False),\n",
    "  StructField(\"error_message\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Initialize metrics dataframe\n",
    "metrics_data = []\n",
    "\n",
    "def log_metrics(operation, status, duration, error_message=None):\n",
    "  \"\"\"Log operation metrics and add to metrics dataframe\"\"\"\n",
    "  metrics_data.append((\n",
    "    datetime.now(),\n",
    "    operation,\n",
    "    status,\n",
    "    duration,\n",
    "    error_message\n",
    "  ))\n",
    "  \n",
    "  if status == \"SUCCESS\":\n",
    "    logger.info(f\"{operation} completed in {duration:.2f} seconds\")\n",
    "  else:\n",
    "    logger.error(f\"{operation} failed after {duration:.2f} seconds: {error_message}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Function to get SpaceX launch data\n",
    "def get_spacex_data():\n",
    "  \"\"\"Fetch SpaceX launch data from the API\"\"\"\n",
    "  start_time = time.time()\n",
    "  operation = \"GET SpaceX API\"\n",
    "  \n",
    "  try:\n",
    "    # Make API request to SpaceX\n",
    "    response = requests.get(\"https://api.spacexdata.com/v4/launches\")\n",
    "    response.raise_for_status()  # Raise exception for non-200 status codes\n",
    "    \n",
    "    # Parse JSON response\n",
    "    launches = response.json()\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    log_metrics(operation, \"SUCCESS\", duration)\n",
    "    \n",
    "    return launches\n",
    "  \n",
    "  except requests.exceptions.RequestException as e:\n",
    "    duration = time.time() - start_time\n",
    "    error_message = str(e)\n",
    "    log_metrics(operation, \"FAILURE\", duration, error_message)\n",
    "    raise Exception(f\"Failed to fetch SpaceX launch data: {error_message}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Function to post data to httpbin.org\n",
    "def post_to_httpbin(data):\n",
    "  \"\"\"Post data to httpbin.org\"\"\"\n",
    "  start_time = time.time()\n",
    "  operation = \"POST to httpbin.org\"\n",
    "  \n",
    "  try:\n",
    "    # Post data to httpbin\n",
    "    response = requests.post(\n",
    "      \"https://httpbin.org/post\",\n",
    "      json=data,\n",
    "      headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse response\n",
    "    result = response.json()\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    log_metrics(operation, \"SUCCESS\", duration)\n",
    "    \n",
    "    return result\n",
    "  \n",
    "  except requests.exceptions.RequestException as e:\n",
    "    duration = time.time() - start_time\n",
    "    error_message = str(e)\n",
    "    log_metrics(operation, \"FAILURE\", duration, error_message)\n",
    "    raise Exception(f\"Failed to post data to httpbin.org: {error_message}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Main pipeline execution function\n",
    "def run_pipeline():\n",
    "  \"\"\"Run the complete data pipeline\"\"\"\n",
    "  overall_start_time = time.time()\n",
    "  operation = \"Complete Pipeline\"\n",
    "  \n",
    "  try:\n",
    "    # Step 1: Get SpaceX launch data\n",
    "    logger.info(\"Starting SpaceX data fetch...\")\n",
    "    launches = get_spacex_data()\n",
    "    logger.info(f\"Successfully retrieved {len(launches)} SpaceX launches\")\n",
    "    \n",
    "    # Optional: Transform or filter data if needed\n",
    "    # For demonstration, we'll just work with the original data\n",
    "    \n",
    "    # Step 2: Post data to httpbin\n",
    "    logger.info(\"Posting data to httpbin.org...\")\n",
    "    httpbin_response = post_to_httpbin(launches)\n",
    "    logger.info(\"Successfully posted data to httpbin.org\")\n",
    "    \n",
    "    # Calculate overall duration\n",
    "    overall_duration = time.time() - overall_start_time\n",
    "    log_metrics(operation, \"SUCCESS\", overall_duration)\n",
    "    \n",
    "    # Create metrics dataframe\n",
    "    metrics_df = spark.createDataFrame(metrics_data, metrics_schema)\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "      \"status\": \"SUCCESS\",\n",
    "      \"pipeline_duration_seconds\": overall_duration,\n",
    "      \"num_launches_processed\": len(launches),\n",
    "      \"httpbin_response\": httpbin_response,\n",
    "      \"metrics_df\": metrics_df\n",
    "    }\n",
    "    \n",
    "  except Exception as e:\n",
    "    overall_duration = time.time() - overall_start_time\n",
    "    error_message = str(e)\n",
    "    log_metrics(operation, \"FAILURE\", overall_duration, error_message)\n",
    "    \n",
    "    # Create metrics dataframe even in case of failure\n",
    "    metrics_df = spark.createDataFrame(metrics_data, metrics_schema)\n",
    "    \n",
    "    return {\n",
    "      \"status\": \"FAILURE\",\n",
    "      \"pipeline_duration_seconds\": overall_duration,\n",
    "      \"error_message\": error_message,\n",
    "      \"metrics_df\": metrics_df\n",
    "    }\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Execute the pipeline\n",
    "pipeline_result = run_pipeline()\n",
    "\n",
    "# Display pipeline status\n",
    "print(f\"Pipeline Status: {pipeline_result['status']}\")\n",
    "print(f\"Pipeline Duration: {pipeline_result['pipeline_duration_seconds']:.2f} seconds\")\n",
    "\n",
    "if pipeline_result['status'] == \"SUCCESS\":\n",
    "  print(f\"Processed {pipeline_result['num_launches_processed']} SpaceX launches\")\n",
    "else:\n",
    "  print(f\"Pipeline Error: {pipeline_result['error_message']}\")\n",
    "\n",
    "# Display metrics\n",
    "display(pipeline_result['metrics_df'])\n",
    "\n",
    "# Save metrics to Delta table (optional)\n",
    "pipeline_result['metrics_df'].write.format(\"delta\").mode(\"append\").saveAsTable(\"pipeline_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cc1614d-9ee6-4cb1-afa5-f65798628cf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "easy prompt CLAUDE",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
