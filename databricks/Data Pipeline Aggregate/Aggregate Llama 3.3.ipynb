{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1137619-5355-4fef-890f-52fe0a9dd7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PROMPT\n",
    "Generate a pipeline for Databricks:\n",
    "* Get Data information from two web addresses:\n",
    "   * Space launches: https://api.spacexdata.com/v3/launches\n",
    "* Aggregate the launches based on launch year\n",
    "* Send the chosen information to the web address: https://httpbin.org/post\n",
    "* The script must provide status updates on its progress, report any errors encountered, confirm the outcome of the final data sending step, and measure/report execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55cb0913-c273-4963-b018-d50ff97cd9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Function to get data from the SpaceX API\n",
    "def get_space_launches():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.get('https://api.spacexdata.com/v3/launches')\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        data = response.json()\n",
    "        print(f\"Successfully fetched data from SpaceX API in {time.time() - start_time} seconds.\")\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from SpaceX API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to aggregate launches by year\n",
    "def aggregate_launches(data):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        # Convert the data into a pandas DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Ensure 'launch_year' column exists and is of appropriate type\n",
    "        if 'launch_year' in df.columns:\n",
    "            df['launch_year'] = pd.to_datetime(df['launch_year'], errors='coerce').dt.year\n",
    "        else:\n",
    "            # If 'launch_year' is not present, extract year from 'launch_date_utc' assuming it's in a parseable format\n",
    "            df['launch_date_utc'] = pd.to_datetime(df['launch_date_utc'], errors='coerce')\n",
    "            df['launch_year'] = df['launch_date_utc'].dt.year\n",
    "        \n",
    "        # Aggregate launches by year\n",
    "        aggregated_df = df['launch_year'].value_counts().reset_index()\n",
    "        aggregated_df.columns = ['launch_year', 'count']\n",
    "        \n",
    "        print(f\"Successfully aggregated launches by year in {time.time() - start_time} seconds.\")\n",
    "        return aggregated_df.to_dict(orient='records')\n",
    "    except Exception as e:\n",
    "        print(f\"Error aggregating launches: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to send data to httpbin\n",
    "def send_data_to_httpbin(data):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = requests.post('https://httpbin.org/post', json=data)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Successfully sent data to httpbin in {time.time() - start_time} seconds. Response: {response.json()}\")\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error sending data to httpbin: {e}\")\n",
    "        return False\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    print(\"Starting pipeline...\")\n",
    "    \n",
    "    # Get SpaceX launches\n",
    "    launches = get_space_launches()\n",
    "    if launches is None:\n",
    "        print(\"Failed to fetch launches. Exiting pipeline.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Aggregate launches\n",
    "    aggregated_launches = aggregate_launches(launches)\n",
    "    if aggregated_launches is None:\n",
    "        print(\"Failed to aggregate launches. Exiting pipeline.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Send aggregated launches to httpbin\n",
    "    success = send_data_to_httpbin(aggregated_launches)\n",
    "    if not success:\n",
    "        print(\"Failed to send data to httpbin. Exiting pipeline with error.\")\n",
    "        exit(1)\n",
    "    \n",
    "    print(f\"Pipeline completed successfully in {time.time() - start_time} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ef737f4-4282-4604-b45c-55377155d6e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Aggregate Llama 3.3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
