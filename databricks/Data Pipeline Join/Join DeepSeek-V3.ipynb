{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1137619-5355-4fef-890f-52fe0a9dd7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PROMPT\n",
    "Generate a pipeline for Databricks\n",
    "* Get Data information from two web addresses:\n",
    "   * Space launches: https://api.spacexdata.com/v3/launches\n",
    "   * All rockets: https://api.spacexdata.com/v3/rockets\n",
    "* Do a join operation between the launches and the rockets\n",
    "* Send the chosen information to the web address: https://httpbin.org/post\n",
    "* The script must provide status updates on its progress, report any errors encountered, confirm the outcome of the final data sending step, and measure/report execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d0255af-4cca-40a7-aa2e-99bdf6135bc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def log_step(message):\n",
    "    \"\"\"Helper function to log pipeline steps with timestamps\"\"\"\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] {message}\")\n",
    "\n",
    "def measure_time(operation_name, func, *args, **kwargs):\n",
    "    \"\"\"Measure and log execution time of a function\"\"\"\n",
    "    start_time = time.time()\n",
    "    log_step(f\"Starting: {operation_name}\")\n",
    "    \n",
    "    try:\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        log_step(f\"Completed: {operation_name} in {elapsed_time:.2f} seconds\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        log_step(f\"Failed: {operation_name} after {elapsed_time:.2f} seconds. Error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def fetch_data(url):\n",
    "    \"\"\"Fetch data from a URL and return as JSON\"\"\"\n",
    "    log_step(f\"Fetching data from {url}\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raises exception for 4XX/5XX errors\n",
    "    return response.json()\n",
    "\n",
    "def send_data(url, data):\n",
    "    \"\"\"Send data to a URL and return response\"\"\"\n",
    "    log_step(f\"Sending data to {url}\")\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize Spark session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"SpaceXDataPipeline\") \\\n",
    "            .getOrCreate()\n",
    "        \n",
    "        log_step(\"Pipeline started\")\n",
    "        \n",
    "        # 1. Fetch data from APIs\n",
    "        launches_data = measure_time(\n",
    "            \"Fetch SpaceX launches data\",\n",
    "            fetch_data,\n",
    "            \"https://api.spacexdata.com/v3/launches\"\n",
    "        )\n",
    "        \n",
    "        rockets_data = measure_time(\n",
    "            \"Fetch SpaceX rockets data\",\n",
    "            fetch_data,\n",
    "            \"https://api.spacexdata.com/v3/rockets\"\n",
    "        )\n",
    "        \n",
    "        # 2. Create DataFrames\n",
    "        launches_df = measure_time(\n",
    "            \"Create launches DataFrame\",\n",
    "            spark.createDataFrame,\n",
    "            launches_data\n",
    "        )\n",
    "        \n",
    "        rockets_df = measure_time(\n",
    "            \"Create rockets DataFrame\",\n",
    "            spark.createDataFrame,\n",
    "            rockets_data\n",
    "        )\n",
    "        \n",
    "        # 3. Join DataFrames\n",
    "        joined_df = measure_time(\n",
    "            \"Join launches and rockets DataFrames\",\n",
    "            lambda: launches_df.join(\n",
    "                rockets_df,\n",
    "                launches_df.rocket.rocket_id == rockets_df.rocket_id,\n",
    "                \"left\"\n",
    "            ).select(\n",
    "                col(\"flight_number\"),\n",
    "                col(\"mission_name\"),\n",
    "                col(\"launch_date_utc\"),\n",
    "                col(\"rocket_name\"),\n",
    "                col(\"success\"),\n",
    "                col(\"details\"),\n",
    "                rockets_df[\"cost_per_launch\"],\n",
    "                rockets_df[\"success_rate_pct\"]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 4. Prepare data for sending\n",
    "        selected_data = measure_time(\n",
    "            \"Collect and prepare data for sending\",\n",
    "            lambda: [row.asDict() for row in joined_df.collect()]\n",
    "        )\n",
    "        \n",
    "        # 5. Send data to endpoint\n",
    "        response = measure_time(\n",
    "            \"Send data to https://httpbin.org/post\",\n",
    "            send_data,\n",
    "            \"https://httpbin.org/post\",\n",
    "            selected_data\n",
    "        )\n",
    "        \n",
    "        log_step(f\"Data successfully sent. Response status: {response.status_code}\")\n",
    "        log_step(f\"Response content: {response.text[:200]}...\")  # Print first 200 chars\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_step(f\"Pipeline failed with error: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        spark.stop()\n",
    "        log_step(\"Pipeline completed (successfully or with errors)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd816018-d568-420e-915f-856ff310cb02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Take the output and give to the LLM to resolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e08f698d-37e3-4862-8950-e5195c27569d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, DoubleType, MapType, ArrayType, TimestampType\n",
    "\n",
    "def log_step(message):\n",
    "    \"\"\"Helper function to log pipeline steps with timestamps\"\"\"\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] {message}\")\n",
    "\n",
    "def measure_time(operation_name, func, *args, **kwargs):\n",
    "    \"\"\"Measure and log execution time of a function\"\"\"\n",
    "    start_time = time.time()\n",
    "    log_step(f\"Starting: {operation_name}\")\n",
    "    \n",
    "    try:\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        log_step(f\"Completed: {operation_name} in {elapsed_time:.2f} seconds\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        log_step(f\"Failed: {operation_name} after {elapsed_time:.2f} seconds. Error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def fetch_data(url):\n",
    "    \"\"\"Fetch data from a URL and return as JSON\"\"\"\n",
    "    log_step(f\"Fetching data from {url}\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def send_data(url, data):\n",
    "    \"\"\"Send data to a URL and return response\"\"\"\n",
    "    log_step(f\"Sending data to {url}\")\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response\n",
    "\n",
    "def get_launches_schema():\n",
    "    \"\"\"Define schema for launches data\"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"flight_number\", IntegerType()),\n",
    "        StructField(\"mission_name\", StringType()),\n",
    "        StructField(\"launch_date_utc\", StringType()),\n",
    "        StructField(\"rocket\", StructType([\n",
    "            StructField(\"rocket_id\", StringType()),\n",
    "            StructField(\"rocket_name\", StringType()),\n",
    "            StructField(\"rocket_type\", StringType())\n",
    "        ])),\n",
    "        StructField(\"launch_success\", BooleanType()),\n",
    "        StructField(\"details\", StringType()),\n",
    "        StructField(\"links\", MapType(StringType(), StringType())),  # Handle complex links object\n",
    "    ])\n",
    "\n",
    "def get_rockets_schema():\n",
    "    \"\"\"Define schema for rockets data\"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"rocket_id\", StringType()),\n",
    "        StructField(\"rocket_name\", StringType()),\n",
    "        StructField(\"cost_per_launch\", IntegerType()),\n",
    "        StructField(\"success_rate_pct\", IntegerType()),\n",
    "        StructField(\"first_flight\", StringType()),\n",
    "        StructField(\"country\", StringType()),\n",
    "        StructField(\"company\", StringType()),\n",
    "    ])\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize Spark session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"SpaceXDataPipeline\") \\\n",
    "            .getOrCreate()\n",
    "        \n",
    "        log_step(\"Pipeline started\")\n",
    "        \n",
    "        # 1. Fetch data from APIs\n",
    "        launches_data = measure_time(\n",
    "            \"Fetch SpaceX launches data\",\n",
    "            fetch_data,\n",
    "            \"https://api.spacexdata.com/v3/launches\"\n",
    "        )\n",
    "        \n",
    "        rockets_data = measure_time(\n",
    "            \"Fetch SpaceX rockets data\",\n",
    "            fetch_data,\n",
    "            \"https://api.spacexdata.com/v3/rockets\"\n",
    "        )\n",
    "        \n",
    "        # 2. Create DataFrames with explicit schemas\n",
    "        launches_df = measure_time(\n",
    "            \"Create launches DataFrame\",\n",
    "            lambda: spark.createDataFrame(\n",
    "                data=launches_data,\n",
    "                schema=get_launches_schema()\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        rockets_df = measure_time(\n",
    "            \"Create rockets DataFrame\",\n",
    "            lambda: spark.createDataFrame(\n",
    "                data=rockets_data,\n",
    "                schema=get_rockets_schema()\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 3. Join DataFrames\n",
    "        joined_df = measure_time(\n",
    "            \"Join launches and rockets DataFrames\",\n",
    "            lambda: launches_df.join(\n",
    "                rockets_df,\n",
    "                launches_df.rocket.rocket_id == rockets_df.rocket_id,\n",
    "                \"left\"\n",
    "            ).select(\n",
    "                col(\"flight_number\"),\n",
    "                col(\"mission_name\"),\n",
    "                col(\"launch_date_utc\"),\n",
    "                col(\"rocket_name\"),\n",
    "                col(\"launch_success\").alias(\"success\"),\n",
    "                col(\"details\"),\n",
    "                col(\"cost_per_launch\"),\n",
    "                col(\"success_rate_pct\")\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 4. Prepare data for sending\n",
    "        selected_data = measure_time(\n",
    "            \"Collect and prepare data for sending\",\n",
    "            lambda: [row.asDict() for row in joined_df.collect()]\n",
    "        )\n",
    "        \n",
    "        # 5. Send data to endpoint\n",
    "        response = measure_time(\n",
    "            \"Send data to https://httpbin.org/post\",\n",
    "            send_data,\n",
    "            \"https://httpbin.org/post\",\n",
    "            selected_data\n",
    "        )\n",
    "        \n",
    "        log_step(f\"Data successfully sent. Response status: {response.status_code}\")\n",
    "        log_step(f\"Response content: {response.text[:200]}...\")  # Print first 200 chars\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_step(f\"Pipeline failed with error: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        spark.stop()\n",
    "        log_step(\"Pipeline completed (successfully or with errors)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4087f9c-ff3a-4df6-8899-34fe20684dde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Join DeepSeek-V3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
