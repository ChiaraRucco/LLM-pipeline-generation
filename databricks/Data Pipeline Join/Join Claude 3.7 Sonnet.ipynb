{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1137619-5355-4fef-890f-52fe0a9dd7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PROMPT\n",
    "Generate a pipeline for Databricks\n",
    "* Get Data information from two web addresses:\n",
    "   * Space launches: https://api.spacexdata.com/v3/launches\n",
    "   * All rockets: https://api.spacexdata.com/v3/rockets\n",
    "* Do a join operation between the launches and the rockets\n",
    "* Send the chosen information to the web address: https://httpbin.org/post\n",
    "* The script must provide status updates on its progress, report any errors encountered, confirm the outcome of the final data sending step, and measure/report execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1388a78e-da7b-46a8-a315-c72ebdd225f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks SpaceX Data Pipeline\n",
    "# This pipeline fetches SpaceX launch and rocket data, joins them, and sends the result to an endpoint\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, explode\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, BooleanType, TimestampType, DoubleType\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SpaceX Data Pipeline\").getOrCreate()\n",
    "\n",
    "def log_message(message):\n",
    "    \"\"\"Log a message with timestamp\"\"\"\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {message}\")\n",
    "\n",
    "def measure_execution_time(func):\n",
    "    \"\"\"Decorator to measure and log execution time of functions\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        log_message(f\"{func.__name__} completed in {execution_time:.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@measure_execution_time\n",
    "def fetch_data(url, endpoint_name):\n",
    "    \"\"\"Fetch JSON data from a URL\"\"\"\n",
    "    log_message(f\"Fetching {endpoint_name} data from {url}\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        data = response.json()\n",
    "        log_message(f\"Successfully fetched {len(data)} {endpoint_name} records\")\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        log_message(f\"Error fetching {endpoint_name} data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@measure_execution_time\n",
    "def create_dataframe(data, schema_fields, data_type):\n",
    "    \"\"\"Create a DataFrame from JSON data\"\"\"\n",
    "    log_message(f\"Creating {data_type} DataFrame\")\n",
    "    try:\n",
    "        schema = StructType(schema_fields)\n",
    "        df = spark.createDataFrame(data, schema)\n",
    "        log_message(f\"Successfully created DataFrame with {df.count()} rows and {len(df.columns)} columns\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error creating {data_type} DataFrame: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@measure_execution_time\n",
    "def join_dataframes(launches_df, rockets_df):\n",
    "    \"\"\"Join launches and rockets DataFrames\"\"\"\n",
    "    log_message(\"Joining launches and rockets DataFrames\")\n",
    "    try:\n",
    "        joined_df = launches_df.join(\n",
    "            rockets_df,\n",
    "            launches_df.rocket_id == rockets_df.rocket_id,\n",
    "            \"inner\"\n",
    "        )\n",
    "        log_message(f\"Successfully joined DataFrames, resulting in {joined_df.count()} rows\")\n",
    "        return joined_df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error joining DataFrames: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@measure_execution_time\n",
    "def process_data(joined_df):\n",
    "    \"\"\"Process and transform the joined data\"\"\"\n",
    "    log_message(\"Processing and transforming joined data\")\n",
    "    try:\n",
    "        # Select relevant columns and rename for clarity\n",
    "        processed_df = joined_df.select(\n",
    "            col(\"flight_number\"),\n",
    "            col(\"mission_name\"),\n",
    "            col(\"launch_year\"),\n",
    "            col(\"launch_success\"),\n",
    "            col(\"details\").alias(\"mission_details\"),\n",
    "            col(\"rocket_name\"),\n",
    "            col(\"rocket_type\"),\n",
    "            col(\"cost_per_launch\"),\n",
    "            col(\"success_rate_pct\"),\n",
    "            col(\"description\").alias(\"rocket_description\")\n",
    "        )\n",
    "        \n",
    "        log_message(f\"Data processing complete. Result has {processed_df.count()} rows\")\n",
    "        return processed_df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error processing data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@measure_execution_time\n",
    "def send_data_to_endpoint(processed_df, url):\n",
    "    \"\"\"Send processed data to an HTTP endpoint\"\"\"\n",
    "    log_message(f\"Sending processed data to {url}\")\n",
    "    try:\n",
    "        # Convert DataFrame to a list of dictionaries\n",
    "        data_to_send = processed_df.limit(100).toPandas().to_dict(orient=\"records\")\n",
    "        \n",
    "        # Send data to the endpoint\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            json=data_to_send,\n",
    "            headers={\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        log_message(f\"Successfully sent data to endpoint. Response status: {response.status_code}\")\n",
    "        log_message(f\"Response body: {response.text[:200]}...\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error sending data to endpoint: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main pipeline function\"\"\"\n",
    "    pipeline_start_time = time.time()\n",
    "    log_message(\"Starting SpaceX data pipeline\")\n",
    "    \n",
    "    try:\n",
    "        # Define API endpoints\n",
    "        launches_url = \"https://api.spacexdata.com/v3/launches\"\n",
    "        rockets_url = \"https://api.spacexdata.com/v3/rockets\"\n",
    "        output_url = \"https://httpbin.org/post\"\n",
    "        \n",
    "        # Define schemas for launches and rockets\n",
    "        launches_schema = [\n",
    "            StructField(\"flight_number\", IntegerType(), True),\n",
    "            StructField(\"mission_name\", StringType(), True),\n",
    "            StructField(\"launch_year\", StringType(), True),\n",
    "            StructField(\"launch_date_utc\", StringType(), True),\n",
    "            StructField(\"launch_success\", BooleanType(), True),\n",
    "            StructField(\"details\", StringType(), True),\n",
    "            StructField(\"rocket\", StructType([\n",
    "                StructField(\"rocket_id\", StringType(), True),\n",
    "                StructField(\"rocket_name\", StringType(), True),\n",
    "                StructField(\"rocket_type\", StringType(), True)\n",
    "            ]), True)\n",
    "        ]\n",
    "        \n",
    "        rockets_schema = [\n",
    "            StructField(\"id\", StringType(), True),\n",
    "            StructField(\"name\", StringType(), True),\n",
    "            StructField(\"type\", StringType(), True),\n",
    "            StructField(\"active\", BooleanType(), True),\n",
    "            StructField(\"cost_per_launch\", IntegerType(), True),\n",
    "            StructField(\"success_rate_pct\", IntegerType(), True),\n",
    "            StructField(\"description\", StringType(), True)\n",
    "        ]\n",
    "        \n",
    "        # Fetch data\n",
    "        launches_data = fetch_data(launches_url, \"launches\")\n",
    "        rockets_data = fetch_data(rockets_url, \"rockets\")\n",
    "        \n",
    "        # Extract rocket ID from nested structure in launches data\n",
    "        for launch in launches_data:\n",
    "            if launch.get(\"rocket\"):\n",
    "                launch[\"rocket_id\"] = launch[\"rocket\"].get(\"rocket_id\")\n",
    "                launch[\"rocket_name\"] = launch[\"rocket\"].get(\"rocket_name\")\n",
    "                launch[\"rocket_type\"] = launch[\"rocket\"].get(\"rocket_type\")\n",
    "        \n",
    "        # Rename rocket id field for joining\n",
    "        for rocket in rockets_data:\n",
    "            rocket[\"rocket_id\"] = rocket.pop(\"id\")\n",
    "            rocket[\"rocket_name\"] = rocket.pop(\"name\")\n",
    "            rocket[\"rocket_type\"] = rocket.pop(\"type\")\n",
    "        \n",
    "        # Create DataFrames\n",
    "        launches_df = create_dataframe(launches_data, launches_schema, \"launches\")\n",
    "        rockets_df = create_dataframe(rockets_data, rockets_schema, \"rockets\")\n",
    "        \n",
    "        # Join DataFrames\n",
    "        joined_df = join_dataframes(launches_df, rockets_df)\n",
    "        \n",
    "        # Process data\n",
    "        processed_df = process_data(joined_df)\n",
    "        \n",
    "        # Display sample data\n",
    "        log_message(\"Sample of processed data:\")\n",
    "        processed_df.show(5, truncate=False)\n",
    "        \n",
    "        # Send data to endpoint\n",
    "        response = send_data_to_endpoint(processed_df, output_url)\n",
    "        \n",
    "        pipeline_end_time = time.time()\n",
    "        total_execution_time = pipeline_end_time - pipeline_start_time\n",
    "        log_message(f\"Pipeline completed successfully in {total_execution_time:.2f} seconds\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26866880-fe0c-41c8-91b1-ef7b597a2dc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Take the output and give to the LLM to resolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af7e375-d71f-4182-8854-34245c1deb2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks SpaceX Data Pipeline\n",
    "# This pipeline fetches SpaceX launch and rocket data, joins them, and sends the result to an endpoint\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, explode\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, BooleanType, TimestampType, DoubleType\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SpaceX Data Pipeline\").getOrCreate()\n",
    "\n",
    "def log_message(message):\n",
    "    \"\"\"Log a message with timestamp\"\"\"\n",
    "    print(f\"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {message}\")\n",
    "\n",
    "def measure_execution_time(func):\n",
    "    \"\"\"Decorator to measure and log execution time of functions\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        log_message(f\"{func.__name__} completed in {execution_time:.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@measure_execution_time\n",
    "def fetch_data(url, endpoint_name):\n",
    "    \"\"\"Fetch JSON data from a URL\"\"\"\n",
    "    log_message(f\"Fetching {endpoint_name} data from {url}\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        data = response.json()\n",
    "        log_message(f\"Successfully fetched {len(data)} {endpoint_name} records\")\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        log_message(f\"Error fetching {endpoint_name} data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@measure_execution_time\n",
    "def process_launches_data(launches_data):\n",
    "    \"\"\"Process launches data to flatten nested rocket information\"\"\"\n",
    "    log_message(\"Processing launches data\")\n",
    "    try:\n",
    "        processed_launches = []\n",
    "        for launch in launches_data:\n",
    "            launch_dict = {\n",
    "                \"flight_number\": launch.get(\"flight_number\"),\n",
    "                \"mission_name\": launch.get(\"mission_name\"),\n",
    "                \"launch_year\": launch.get(\"launch_year\"),\n",
    "                \"launch_date_utc\": launch.get(\"launch_date_utc\"),\n",
    "                \"launch_success\": launch.get(\"launch_success\"),\n",
    "                \"details\": launch.get(\"details\"),\n",
    "                \"rocket_id\": launch.get(\"rocket\", {}).get(\"rocket_id\"),\n",
    "                \"rocket_name\": launch.get(\"rocket\", {}).get(\"rocket_name\"),\n",
    "                \"rocket_type\": launch.get(\"rocket\", {}).get(\"rocket_type\")\n",
    "            }\n",
    "            processed_launches.append(launch_dict)\n",
    "        \n",
    "        log_message(f\"Successfully processed {len(processed_launches)} launch records\")\n",
    "        return processed_launches\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error processing launches data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@measure_execution_time\n",
    "def create_dataframe(data, schema_fields, data_type):\n",
    "    \"\"\"Create a DataFrame from JSON data\"\"\"\n",
    "    log_message(f\"Creating {data_type} DataFrame\")\n",
    "    try:\n",
    "        schema = StructType(schema_fields)\n",
    "        df = spark.createDataFrame(data, schema)\n",
    "        log_message(f\"Successfully created DataFrame with {df.count()} rows and {len(df.columns)} columns\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error creating {data_type} DataFrame: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@measure_execution_time\n",
    "def join_dataframes(launches_df, rockets_df):\n",
    "    \"\"\"Join launches and rockets DataFrames\"\"\"\n",
    "    log_message(\"Joining launches and rockets DataFrames\")\n",
    "    try:\n",
    "        joined_df = launches_df.join(\n",
    "            rockets_df,\n",
    "            launches_df.rocket_id == rockets_df.id,\n",
    "            \"inner\"\n",
    "        )\n",
    "        log_message(f\"Successfully joined DataFrames, resulting in {joined_df.count()} rows\")\n",
    "        return joined_df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error joining DataFrames: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@measure_execution_time\n",
    "def process_data(joined_df):\n",
    "    \"\"\"Process and transform the joined data\"\"\"\n",
    "    log_message(\"Processing and transforming joined data\")\n",
    "    try:\n",
    "        # Select relevant columns and rename for clarity\n",
    "        processed_df = joined_df.select(\n",
    "            col(\"flight_number\"),\n",
    "            col(\"mission_name\"),\n",
    "            col(\"launch_year\"),\n",
    "            col(\"launch_success\"),\n",
    "            col(\"details\").alias(\"mission_details\"),\n",
    "            col(\"rocket_name\"),\n",
    "            col(\"rocket_type\"),\n",
    "            col(\"cost_per_launch\"),\n",
    "            col(\"success_rate_pct\"),\n",
    "            col(\"description\").alias(\"rocket_description\")\n",
    "        )\n",
    "        \n",
    "        log_message(f\"Data processing complete. Result has {processed_df.count()} rows\")\n",
    "        return processed_df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error processing data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@measure_execution_time\n",
    "def send_data_to_endpoint(processed_df, url):\n",
    "    \"\"\"Send processed data to an HTTP endpoint\"\"\"\n",
    "    log_message(f\"Sending processed data to {url}\")\n",
    "    try:\n",
    "        # Convert DataFrame to a list of dictionaries\n",
    "        data_to_send = processed_df.limit(100).toPandas().to_dict(orient=\"records\")\n",
    "        \n",
    "        # Send data to the endpoint\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            json=data_to_send,\n",
    "            headers={\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        log_message(f\"Successfully sent data to endpoint. Response status: {response.status_code}\")\n",
    "        log_message(f\"Response body: {response.text[:200]}...\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error sending data to endpoint: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main pipeline function\"\"\"\n",
    "    pipeline_start_time = time.time()\n",
    "    log_message(\"Starting SpaceX data pipeline\")\n",
    "    \n",
    "    try:\n",
    "        # Define API endpoints\n",
    "        launches_url = \"https://api.spacexdata.com/v3/launches\"\n",
    "        rockets_url = \"https://api.spacexdata.com/v3/rockets\"\n",
    "        output_url = \"https://httpbin.org/post\"\n",
    "        \n",
    "        # Define schemas for launches and rockets\n",
    "        launches_schema = [\n",
    "            StructField(\"flight_number\", IntegerType(), True),\n",
    "            StructField(\"mission_name\", StringType(), True),\n",
    "            StructField(\"launch_year\", StringType(), True),\n",
    "            StructField(\"launch_date_utc\", StringType(), True),\n",
    "            StructField(\"launch_success\", BooleanType(), True),\n",
    "            StructField(\"details\", StringType(), True),\n",
    "            StructField(\"rocket_id\", StringType(), True),\n",
    "            StructField(\"rocket_name\", StringType(), True),\n",
    "            StructField(\"rocket_type\", StringType(), True)\n",
    "        ]\n",
    "        \n",
    "        rockets_schema = [\n",
    "            StructField(\"id\", StringType(), True),\n",
    "            StructField(\"name\", StringType(), True),\n",
    "            StructField(\"type\", StringType(), True),\n",
    "            StructField(\"active\", BooleanType(), True),\n",
    "            StructField(\"cost_per_launch\", IntegerType(), True),\n",
    "            StructField(\"success_rate_pct\", IntegerType(), True),\n",
    "            StructField(\"description\", StringType(), True)\n",
    "        ]\n",
    "        \n",
    "        # Fetch data\n",
    "        launches_data = fetch_data(launches_url, \"launches\")\n",
    "        rockets_data = fetch_data(rockets_url, \"rockets\")\n",
    "        \n",
    "        # Process launches data to flatten nested rocket information\n",
    "        processed_launches = process_launches_data(launches_data)\n",
    "        \n",
    "        # Create DataFrames\n",
    "        launches_df = create_dataframe(processed_launches, launches_schema, \"launches\")\n",
    "        rockets_df = create_dataframe(rockets_data, rockets_schema, \"rockets\")\n",
    "        \n",
    "        # Join DataFrames\n",
    "        joined_df = join_dataframes(launches_df, rockets_df)\n",
    "        \n",
    "        # Process data\n",
    "        processed_df = process_data(joined_df)\n",
    "        \n",
    "        # Display sample data\n",
    "        log_message(\"Sample of processed data:\")\n",
    "        processed_df.show(5, truncate=False)\n",
    "        \n",
    "        # Send data to endpoint\n",
    "        response = send_data_to_endpoint(processed_df, output_url)\n",
    "        \n",
    "        pipeline_end_time = time.time()\n",
    "        total_execution_time = pipeline_end_time - pipeline_start_time\n",
    "        log_message(f\"Pipeline completed successfully in {total_execution_time:.2f} seconds\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(f\"Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f82ae6ea-796e-426b-95ae-0d9cf04da396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Join Claude 3.7 Sonnet",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
