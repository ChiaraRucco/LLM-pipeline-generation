{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1137619-5355-4fef-890f-52fe0a9dd7a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PROMPT\n",
    "Generate a pipeline for Databricks:\n",
    "* Get Data information from two web addresses:\n",
    "   * Space launches: https://api.spacexdata.com/v3/launches\n",
    "* Filter the list of launches based on launch year and launch success status.\n",
    "* Send the chosen information to the web address: https://httpbin.org/post\n",
    "* The script must provide status updates on its progress, report any errors encountered, confirm the outcome of the final data sending step, and measure/report execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e0d1e58-f3c6-4679-a472-55e2aef10def",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SpaceX Data Pipeline for Databricks\n",
    "# This pipeline fetches SpaceX launch data, filters it, and posts the results to httpbin\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"SpaceXPipeline\")\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SpaceXDataPipeline\").getOrCreate()\n",
    "\n",
    "def get_spacex_data():\n",
    "    \"\"\"Fetch SpaceX launch data from API\"\"\"\n",
    "    start_time = time.time()\n",
    "    logger.info(\"Starting data collection from SpaceX API\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\"https://api.spacexdata.com/v3/launches\", timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        logger.info(f\"Successfully retrieved {len(data)} launch records from SpaceX API\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Data collection completed in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error fetching data from SpaceX API: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def filter_launch_data(data, year=None, success=None):\n",
    "    \"\"\"Filter launch data based on year and success status\"\"\"\n",
    "    start_time = time.time()\n",
    "    logger.info(f\"Filtering data with parameters - year: {year}, success: {success}\")\n",
    "    \n",
    "    # Convert to DataFrame for easier filtering\n",
    "    df = spark.createDataFrame(data)\n",
    "    \n",
    "    # Apply filters if specified\n",
    "    if year is not None:\n",
    "        df = df.filter(col(\"launch_year\") == str(year))\n",
    "    \n",
    "    if success is not None:\n",
    "        df = df.filter(col(\"launch_success\") == success)\n",
    "    \n",
    "    # Convert back to Python objects\n",
    "    filtered_data = df.collect()\n",
    "    filtered_data = [row.asDict() for row in filtered_data]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    logger.info(f\"Filtering completed in {elapsed_time:.2f} seconds\")\n",
    "    logger.info(f\"Filtered data contains {len(filtered_data)} records\")\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "def send_data_to_endpoint(data):\n",
    "    \"\"\"Send filtered data to external endpoint\"\"\"\n",
    "    start_time = time.time()\n",
    "    logger.info(\"Sending filtered data to external endpoint\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare payload\n",
    "        payload = {\n",
    "            \"source\": \"SpaceX API\",\n",
    "            \"processed_date\": datetime.now().isoformat(),\n",
    "            \"record_count\": len(data),\n",
    "            \"data\": data\n",
    "        }\n",
    "        \n",
    "        # Send data\n",
    "        response = requests.post(\n",
    "            \"https://httpbin.org/post\", \n",
    "            json=payload,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Log response\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Data successfully sent to endpoint in {elapsed_time:.2f} seconds\")\n",
    "        logger.info(f\"Response status code: {response.status_code}\")\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error sending data to endpoint: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def run_pipeline(filter_year=2020, filter_success=True):\n",
    "    \"\"\"Execute the complete data pipeline\"\"\"\n",
    "    overall_start_time = time.time()\n",
    "    logger.info(\"Starting SpaceX data pipeline execution\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Get data\n",
    "        spacex_data = get_spacex_data()\n",
    "        \n",
    "        # Step 2: Filter data\n",
    "        filtered_data = filter_launch_data(spacex_data, year=filter_year, success=filter_success)\n",
    "        \n",
    "        # Step 3: Send data to endpoint\n",
    "        if filtered_data:\n",
    "            response = send_data_to_endpoint(filtered_data)\n",
    "            logger.info(\"Pipeline execution completed successfully\")\n",
    "        else:\n",
    "            logger.warning(\"No data to send after filtering\")\n",
    "        \n",
    "        # Calculate total execution time\n",
    "        total_execution_time = time.time() - overall_start_time\n",
    "        logger.info(f\"Total pipeline execution time: {total_execution_time:.2f} seconds\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"execution_time\": total_execution_time,\n",
    "            \"records_processed\": len(filtered_data),\n",
    "            \"filter_criteria\": {\n",
    "                \"year\": filter_year,\n",
    "                \"success\": filter_success\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline execution failed: {str(e)}\")\n",
    "        \n",
    "        # Calculate execution time even for failed runs\n",
    "        total_execution_time = time.time() - overall_start_time\n",
    "        logger.info(f\"Failed pipeline execution time: {total_execution_time:.2f} seconds\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"failed\",\n",
    "            \"execution_time\": total_execution_time,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Execute the pipeline (can be parameterized as needed)\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Run pipeline for successful launches from 2020\n",
    "    result = run_pipeline(filter_year=2020, filter_success=True)\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66bd01a0-377d-4258-882f-e0c10466d18a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1 error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa24df88-4de7-4bc7-8f64-b9f58d08c45e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SpaceX Data Pipeline for Databricks\n",
    "# This pipeline fetches SpaceX launch data, filters it, and posts the results to httpbin\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, to_json, struct\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"SpaceXPipeline\")\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SpaceXDataPipeline\").getOrCreate()\n",
    "\n",
    "def get_spacex_data():\n",
    "    \"\"\"Fetch SpaceX launch data from API\"\"\"\n",
    "    start_time = time.time()\n",
    "    logger.info(\"Starting data collection from SpaceX API\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\"https://api.spacexdata.com/v3/launches\", timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        logger.info(f\"Successfully retrieved {len(data)} launch records from SpaceX API\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Data collection completed in {elapsed_time:.2f} seconds\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error fetching data from SpaceX API: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def extract_launch_details(data):\n",
    "    \"\"\"Extract only the required fields from complex launch data\"\"\"\n",
    "    simplified_data = []\n",
    "    \n",
    "    for launch in data:\n",
    "        # Extract only the fields we need\n",
    "        simplified_launch = {\n",
    "            \"flight_number\": launch.get(\"flight_number\"),\n",
    "            \"mission_name\": launch.get(\"mission_name\"),\n",
    "            \"launch_year\": launch.get(\"launch_year\"),\n",
    "            \"launch_date_utc\": launch.get(\"launch_date_utc\"),\n",
    "            \"launch_success\": launch.get(\"launch_success\"),\n",
    "            \"rocket_name\": launch.get(\"rocket\", {}).get(\"rocket_name\"),\n",
    "            \"details\": launch.get(\"details\"),\n",
    "            # Add any other fields you need\n",
    "        }\n",
    "        simplified_data.append(simplified_launch)\n",
    "    \n",
    "    return simplified_data\n",
    "\n",
    "def filter_launch_data(data, year=None, success=None):\n",
    "    \"\"\"Filter launch data based on year and success status\"\"\"\n",
    "    start_time = time.time()\n",
    "    logger.info(f\"Filtering data with parameters - year: {year}, success: {success}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract only the fields we need to avoid schema inference issues\n",
    "        simplified_data = extract_launch_details(data)\n",
    "        \n",
    "        # Convert to pandas DataFrame first\n",
    "        pandas_df = pd.DataFrame(simplified_data)\n",
    "        \n",
    "        # Convert pandas DataFrame to Spark DataFrame\n",
    "        df = spark.createDataFrame(pandas_df)\n",
    "        \n",
    "        # Apply filters if specified\n",
    "        if year is not None:\n",
    "            df = df.filter(col(\"launch_year\") == str(year))\n",
    "        \n",
    "        if success is not None:\n",
    "            df = df.filter(col(\"launch_success\") == success)\n",
    "        \n",
    "        # Convert back to Python objects\n",
    "        filtered_data = df.toPandas().to_dict('records')\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Filtering completed in {elapsed_time:.2f} seconds\")\n",
    "        logger.info(f\"Filtered data contains {len(filtered_data)} records\")\n",
    "        \n",
    "        return filtered_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error filtering data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def send_data_to_endpoint(data):\n",
    "    \"\"\"Send filtered data to external endpoint\"\"\"\n",
    "    start_time = time.time()\n",
    "    logger.info(\"Sending filtered data to external endpoint\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare payload\n",
    "        payload = {\n",
    "            \"source\": \"SpaceX API\",\n",
    "            \"processed_date\": datetime.now().isoformat(),\n",
    "            \"record_count\": len(data),\n",
    "            \"data\": data\n",
    "        }\n",
    "        \n",
    "        # Send data\n",
    "        response = requests.post(\n",
    "            \"https://httpbin.org/post\", \n",
    "            json=payload,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Log response\n",
    "        elapsed_time = time.time() - start_time\n",
    "        logger.info(f\"Data successfully sent to endpoint in {elapsed_time:.2f} seconds\")\n",
    "        logger.info(f\"Response status code: {response.status_code}\")\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error sending data to endpoint: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def run_pipeline(filter_year=2020, filter_success=True):\n",
    "    \"\"\"Execute the complete data pipeline\"\"\"\n",
    "    overall_start_time = time.time()\n",
    "    logger.info(\"Starting SpaceX data pipeline execution\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Get data\n",
    "        spacex_data = get_spacex_data()\n",
    "        \n",
    "        # Step 2: Filter data\n",
    "        filtered_data = filter_launch_data(spacex_data, year=filter_year, success=filter_success)\n",
    "        \n",
    "        # Step 3: Send data to endpoint\n",
    "        if filtered_data:\n",
    "            response = send_data_to_endpoint(filtered_data)\n",
    "            logger.info(\"Pipeline execution completed successfully\")\n",
    "        else:\n",
    "            logger.warning(\"No data to send after filtering\")\n",
    "        \n",
    "        # Calculate total execution time\n",
    "        total_execution_time = time.time() - overall_start_time\n",
    "        logger.info(f\"Total pipeline execution time: {total_execution_time:.2f} seconds\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"execution_time\": total_execution_time,\n",
    "            \"records_processed\": len(filtered_data),\n",
    "            \"filter_criteria\": {\n",
    "                \"year\": filter_year,\n",
    "                \"success\": filter_success\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline execution failed: {str(e)}\")\n",
    "        \n",
    "        # Calculate execution time even for failed runs\n",
    "        total_execution_time = time.time() - overall_start_time\n",
    "        logger.info(f\"Failed pipeline execution time: {total_execution_time:.2f} seconds\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"failed\",\n",
    "            \"execution_time\": total_execution_time,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# Execute the pipeline (can be parameterized as needed)\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: Run pipeline for successful launches from 2020\n",
    "    result = run_pipeline(filter_year=2020, filter_success=True)\n",
    "    print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Filter Claude 3.7 Sonnet",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
