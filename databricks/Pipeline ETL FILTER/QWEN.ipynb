{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6013620-52de-4e21-aa7c-ea5c0d9a24a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are an expert Python developer specializing in the Databricks environment. Your task is to create a complete Python script to be executed within a Databricks notebook. The script must perform the following operations:\n",
    "1.\tData Retrieval from SpaceX API:\n",
    "o\tInteract with the SpaceX v3 REST API (https://api.spacexdata.com/v3).\n",
    "o\tRetrieve data from one specific endpoint: \n",
    "\tAll launches: https://api.spacexdata.com/v3/launches\n",
    "o\tHandle potential errors during the API calls (e.g., timeouts, non-200 status codes).\n",
    "2.\tFilter Operation:\n",
    "o\tPerform a \"filter\" operation on the retrieved launch data based on specific criteria.\n",
    "o\tFilter Logic: Filter the list of launches based on launch year and launch success status. Only include launches that match the specified criteria.\n",
    "o\tThe result should be a list of dictionaries, containing only the launch records that satisfy the filter conditions.\n",
    "3.\tControl Parameters and Debugging:\n",
    "o\tInclude variables at the beginning of the script to define the API endpoint URL and the filtering criteria, making them easily modifiable. Use parameters like: \n",
    "\tAPI_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "\tFILTER_YEAR = 2019 (Set to an integer year, or None to disable year filtering)\n",
    "\tFILTER_SUCCESS = True (Set to True, False, or None to disable success filtering)\n",
    "o\tUse Python's standard logging module to provide informative output during execution. Configure logging to display messages at the INFO level.\n",
    "o\tLog key messages such as: starting data retrieval, number of launches retrieved, filtering criteria being applied, number of launches before filtering, number of launches after filtering, starting upload to httpbin, upload outcome.\n",
    "4.\tExecution Time Measurement:\n",
    "o\tCode Execution Time: Measure the time taken to perform the main operations (data retrieval + filtering). Print this time after the filtering operation is complete.\n",
    "o\tPipeline Execution Time: Measure the total execution time of the entire script (from the beginning until after the upload to httpbin). Print this total time at the end of the script. Use Python's time module.\n",
    "5.\tUpload Result:\n",
    "o\tTake the resulting filtered list from the filter operation.\n",
    "o\tSerialize it into JSON format.\n",
    "o\tMake an HTTP POST request to the https://httpbin.org/post endpoint, sending the resulting filtered JSON data in the request body.\n",
    "o\tVerify the response from httpbin.org (e.g., check the status code) and log the outcome of the upload operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acadff3a-4609-4a37-a316-cd5989c71be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Control Parameters\n",
    "API_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "FILTER_YEAR = 2019  # Set to an integer year, or None to disable year filtering\n",
    "FILTER_SUCCESS = True  # Set to True, False, or None to disable success filtering\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Measure total pipeline execution time\n",
    "pipeline_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Log start of data retrieval\n",
    "    logging.info(\"Starting data retrieval from SpaceX API...\")\n",
    "    retrieval_start_time = time.time()\n",
    "\n",
    "    # Make API call to retrieve launch data\n",
    "    try:\n",
    "        response = requests.get(API_ENDPOINT_URL, timeout=10)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        launches = response.json()\n",
    "        logging.info(f\"Data retrieval successful. Retrieved {len(launches)} launches.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error during API call: {e}\")\n",
    "        raise\n",
    "\n",
    "    retrieval_end_time = time.time()\n",
    "    logging.info(f\"Data retrieval completed in {retrieval_end_time - retrieval_start_time:.2f} seconds.\")\n",
    "\n",
    "    # Filter operation\n",
    "    logging.info(\"Starting filtering operation...\")\n",
    "    filter_start_time = time.time()\n",
    "\n",
    "    # Apply filtering criteria\n",
    "    filtered_launches = []\n",
    "    for launch in launches:\n",
    "        include_launch = True\n",
    "\n",
    "        # Apply year filter if FILTER_YEAR is set\n",
    "        if FILTER_YEAR is not None and launch.get(\"launch_year\") != str(FILTER_YEAR):\n",
    "            include_launch = False\n",
    "\n",
    "        # Apply success filter if FILTER_SUCCESS is set\n",
    "        if FILTER_SUCCESS is not None and launch.get(\"launch_success\") != FILTER_SUCCESS:\n",
    "            include_launch = False\n",
    "\n",
    "        if include_launch:\n",
    "            filtered_launches.append(launch)\n",
    "\n",
    "    filter_end_time = time.time()\n",
    "    logging.info(f\"Filtering completed in {filter_end_time - filter_start_time:.2f} seconds.\")\n",
    "    logging.info(f\"Number of launches before filtering: {len(launches)}\")\n",
    "    logging.info(f\"Number of launches after filtering: {len(filtered_launches)}\")\n",
    "\n",
    "    # Serialize filtered data to JSON\n",
    "    filtered_data_json = json.dumps(filtered_launches)\n",
    "\n",
    "    # Upload result to httpbin.org\n",
    "    logging.info(\"Starting upload to httpbin.org...\")\n",
    "    upload_start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        upload_response = requests.post(\"https://httpbin.org/post\", data=filtered_data_json, timeout=10)\n",
    "        upload_response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        logging.info(f\"Upload successful. Response status code: {upload_response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error during upload to httpbin.org: {e}\")\n",
    "        raise\n",
    "\n",
    "    upload_end_time = time.time()\n",
    "    logging.info(f\"Upload completed in {upload_end_time - upload_start_time:.2f} seconds.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during execution: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Measure total pipeline execution time\n",
    "    pipeline_end_time = time.time()\n",
    "    logging.info(f\"Total pipeline execution time: {pipeline_end_time - pipeline_start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a67672fe-b3d7-40c5-a99e-3a65b9e218a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The code need a fix so i try to put the output in qwen again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd61cbe-c2c1-4973-84e9-6e0224f7c03e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Control parameters (easily modifiable)\n",
    "LAUNCHES_API_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "ROCKETS_API_URL = \"https://api.spacexdata.com/v3/rockets\"\n",
    "HTTPBIN_POST_URL = \"https://httpbin.org/post\"\n",
    "\n",
    "def fetch_data(api_url):\n",
    "    \"\"\"\n",
    "    Fetch data from a given API endpoint.\n",
    "    Handles errors such as timeouts or non-200 status codes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Fetching data from: {api_url}\")\n",
    "        response = requests.get(api_url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error fetching data from {api_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def merge_launches_and_rockets(launches, rockets):\n",
    "    \"\"\"\n",
    "    Merge launches and rockets data based on rocket_id.\n",
    "    Adds rocket_name to each launch record.\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting merge operation...\")\n",
    "    \n",
    "    # Create a dictionary for quick lookup of rocket names by rocket_id\n",
    "    rocket_lookup = {}\n",
    "    for rocket in rockets:\n",
    "        try:\n",
    "            rocket_id = rocket['id']\n",
    "            rocket_name = rocket.get('name', 'Unknown Rocket')  # Use 'Unknown Rocket' as fallback\n",
    "            rocket_lookup[rocket_id] = rocket_name\n",
    "        except KeyError as e:\n",
    "            logging.warning(f\"Missing key in rocket data: {e}. Skipping this rocket.\")\n",
    "    \n",
    "    # Enrich each launch record with the corresponding rocket name\n",
    "    merged_data = []\n",
    "    for launch in launches:\n",
    "        try:\n",
    "            rocket_id = launch.get('rocket', {}).get('rocket_id')\n",
    "            rocket_name = rocket_lookup.get(rocket_id, 'Unknown Rocket')\n",
    "            enriched_launch = {**launch, 'rocket_name': rocket_name}\n",
    "            merged_data.append(enriched_launch)\n",
    "        except KeyError as e:\n",
    "            logging.warning(f\"Missing key in launch data: {e}. Skipping this launch.\")\n",
    "    \n",
    "    logging.info(f\"Merge operation completed. Total records after merge: {len(merged_data)}\")\n",
    "    return merged_data\n",
    "\n",
    "def upload_to_httpbin(data):\n",
    "    \"\"\"\n",
    "    Serialize data to JSON and upload it to httpbin.org/post.\n",
    "    Logs the outcome of the upload operation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(\"Starting upload to httpbin.org...\")\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        response = requests.post(HTTPBIN_POST_URL, data=json.dumps(data), headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        logging.info(f\"Upload successful. Status code: {response.status_code}\")\n",
    "        logging.debug(f\"Response from httpbin: {response.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error during upload to httpbin.org: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Start measuring total pipeline execution time\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    # Step 1: Retrieve data from SpaceX API\n",
    "    logging.info(\"Starting data retrieval from SpaceX API...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    launches = fetch_data(LAUNCHES_API_URL)\n",
    "    rockets = fetch_data(ROCKETS_API_URL)\n",
    "    \n",
    "    if launches is None or rockets is None:\n",
    "        logging.error(\"Data retrieval failed. Exiting script.\")\n",
    "        return\n",
    "    \n",
    "    # Log sample rocket data for inspection\n",
    "    logging.info(f\"Sample rocket data: {rockets[:2]}\")\n",
    "    \n",
    "    logging.info(f\"Number of launches retrieved: {len(launches)}\")\n",
    "    logging.info(f\"Number of rockets retrieved: {len(rockets)}\")\n",
    "    \n",
    "    # Measure data retrieval time\n",
    "    data_retrieval_time = time.time() - start_time\n",
    "    logging.info(f\"Data retrieval completed in {data_retrieval_time:.2f} seconds.\")\n",
    "    \n",
    "    # Step 2: Merge launches and rockets data\n",
    "    start_time = time.time()\n",
    "    merged_data = merge_launches_and_rockets(launches, rockets)\n",
    "    \n",
    "    # Measure merge operation time\n",
    "    merge_time = time.time() - start_time\n",
    "    logging.info(f\"Merge operation completed in {merge_time:.2f} seconds.\")\n",
    "    \n",
    "    # Step 3: Upload merged data to httpbin.org\n",
    "    upload_to_httpbin(merged_data)\n",
    "    \n",
    "    # Measure total pipeline execution time\n",
    "    total_execution_time = time.time() - total_start_time\n",
    "    logging.info(f\"Total pipeline execution time: {total_execution_time:.2f} seconds.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c62f090e-3280-4ae8-b6a0-f0323975b8c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "QWEN",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
