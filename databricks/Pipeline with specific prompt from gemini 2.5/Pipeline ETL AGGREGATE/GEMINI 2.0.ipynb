{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6013620-52de-4e21-aa7c-ea5c0d9a24a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are an expert Python developer specializing in the Databricks environment. Your task is to create a complete Python script to be executed within a Databricks notebook. The script must perform the following operations:\n",
    "1.\tData Retrieval from SpaceX API:\n",
    "o\tInteract with the SpaceX v3 REST API (https://api.spacexdata.com/v3).\n",
    "o\tRetrieve data from one specific endpoint: \n",
    "\tAll launches: https://api.spacexdata.com/v3/launches\n",
    "o\tHandle potential errors during the API calls (e.g., timeouts, non-200 status codes).\n",
    "2.\tAggregate Operation:\n",
    "o\tPerform a simple \"aggregate\" operation on the retrieved launch data.\n",
    "o\tAggregation Logic: Calculate the total number of launches for each year.\n",
    "o\tReturn a print with the number of aggregate launches for each year\n",
    "3.\tControl Parameters and Debugging:\n",
    "o\tInclude a variable at the beginning of the script to define the API endpoint URL, making it easily modifiable: \n",
    "\tAPI_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "o\tUse Python's standard logging module to provide informative output during execution. Configure logging to display messages at the INFO level.\n",
    "o\tLog key messages such as: starting data retrieval, number of launches retrieved, starting aggregation, aggregation complete, number of years aggregated, starting upload to httpbin, upload outcome.\n",
    "4.\tExecution Time Measurement:\n",
    "o\tCode Execution Time: Measure the time taken to perform the main operations (data retrieval + aggregation). Print this time after the aggregation operation is complete.\n",
    "o\tPipeline Execution Time: Measure the total execution time of the entire script (from the beginning until after the upload to httpbin). Print this total time at the end of the script. Use Python's time module.\n",
    "5.\tUpload Result:\n",
    "o\tTake the resulting aggregated summary dictionary (year counts) from the aggregate operation.\n",
    "o\tSerialize it into JSON format.\n",
    "o\tMake an HTTP POST request to the https://httpbin.org/post endpoint, sending the resulting aggregated JSON data in the request body.\n",
    "o\tVerify the response from httpbin.org (e.g., check the status code) and log the outcome of the upload operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acadff3a-4609-4a37-a316-cd5989c71be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# Define the API endpoint URL\n",
    "API_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "HTTPBIN_UPLOAD_URL = \"https://httpbin.org/post\"\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def retrieve_spacex_data(api_url):\n",
    "    \"\"\"Retrieves data from the specified SpaceX API endpoint.\"\"\"\n",
    "    logging.info(f\"Starting data retrieval from: {api_url}\")\n",
    "    try:\n",
    "        response = requests.get(api_url, timeout=10)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        data = response.json()\n",
    "        logging.info(f\"Successfully retrieved {len(data)} launches.\")\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error during API call: {e}\")\n",
    "        return None\n",
    "\n",
    "def aggregate_launches_by_year(launches):\n",
    "    \"\"\"Aggregates the number of launches for each year.\"\"\"\n",
    "    logging.info(\"Starting aggregation of launch data.\")\n",
    "    launches_by_year = {}\n",
    "    if launches:\n",
    "        for launch in launches:\n",
    "            # Assuming launch_date_utc is in a format that can be parsed to get the year\n",
    "            # Example format: '2006-03-24T22:30:00.000Z'\n",
    "            try:\n",
    "                launch_year = launch['launch_date_utc'][:4]\n",
    "                launches_by_year[launch_year] = launches_by_year.get(launch_year, 0) + 1\n",
    "            except (KeyError, TypeError):\n",
    "                logging.warning(f\"Could not extract launch year for launch: {launch.get('flight_number', 'N/A')}\")\n",
    "    logging.info(\"Aggregation complete.\")\n",
    "    logging.info(f\"Aggregated data for {len(launches_by_year)} years.\")\n",
    "    print(\"Number of launches per year:\")\n",
    "    for year, count in launches_by_year.items():\n",
    "        print(f\"Year {year}: {count}\")\n",
    "    return launches_by_year\n",
    "\n",
    "def upload_data_to_httpbin(data):\n",
    "    \"\"\"Uploads the provided data to httpbin.org/post as JSON.\"\"\"\n",
    "    logging.info(f\"Starting upload to {HTTPBIN_UPLOAD_URL}\")\n",
    "    try:\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        json_data = json.dumps(data)\n",
    "        response = requests.post(HTTPBIN_UPLOAD_URL, headers=headers, data=json_data, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        logging.info(f\"Upload to httpbin.org successful. Status code: {response.status_code}\")\n",
    "        logging.debug(f\"httpbin response: {response.json()}\")\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error during upload to httpbin.org: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline_start_time = time.time()\n",
    "\n",
    "    # Data Retrieval\n",
    "    data_retrieval_start_time = time.time()\n",
    "    launches_data = retrieve_spacex_data(API_ENDPOINT_URL)\n",
    "    data_retrieval_end_time = time.time()\n",
    "\n",
    "    if launches_data:\n",
    "        # Aggregation\n",
    "        aggregation_start_time = time.time()\n",
    "        aggregated_data = aggregate_launches_by_year(launches_data)\n",
    "        aggregation_end_time = time.time()\n",
    "\n",
    "        # Calculate and print execution time for data retrieval and aggregation\n",
    "        data_aggregation_time = aggregation_end_time - data_retrieval_start_time\n",
    "        print(f\"\\nTime taken for data retrieval and aggregation: {data_aggregation_time:.2f} seconds\")\n",
    "    else:\n",
    "        aggregated_data = {}\n",
    "        print(\"\\nSkipping aggregation due to data retrieval failure.\")\n",
    "\n",
    "    # Upload Result\n",
    "    if aggregated_data:\n",
    "        upload_start_time = time.time()\n",
    "        upload_successful = upload_data_to_httpbin(aggregated_data)\n",
    "        upload_end_time = time.time()\n",
    "        logging.info(f\"Upload outcome: {'Success' if upload_successful else 'Failure'}\")\n",
    "    else:\n",
    "        logging.warning(\"No aggregated data to upload.\")\n",
    "\n",
    "    pipeline_end_time = time.time()\n",
    "    total_execution_time = pipeline_end_time - pipeline_start_time\n",
    "    print(f\"\\nTotal execution time of the script: {total_execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cd61cbe-c2c1-4973-84e9-6e0224f7c03e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GEMINI 2.0",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
