{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6013620-52de-4e21-aa7c-ea5c0d9a24a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are an expert Python developer specializing in the Databricks environment. Your task is to create a complete Python script to be executed within a Databricks notebook. The script must perform the following operations:\n",
    "1.\tData Retrieval from SpaceX API:\n",
    "o\tInteract with the SpaceX v3 REST API (https://api.spacexdata.com/v3).\n",
    "o\tRetrieve data from one specific endpoint: \n",
    "\tAll launches: https://api.spacexdata.com/v3/launches\n",
    "o\tHandle potential errors during the API calls (e.g., timeouts, non-200 status codes).\n",
    "2.\tAggregate Operation:\n",
    "o\tPerform a simple \"aggregate\" operation on the retrieved launch data.\n",
    "o\tAggregation Logic: Calculate the total number of launches for each year.\n",
    "o\tReturn a print with the number of aggregate launches for each year\n",
    "3.\tControl Parameters and Debugging:\n",
    "o\tInclude a variable at the beginning of the script to define the API endpoint URL, making it easily modifiable: \n",
    "\tAPI_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "o\tUse Python's standard logging module to provide informative output during execution. Configure logging to display messages at the INFO level.\n",
    "o\tLog key messages such as: starting data retrieval, number of launches retrieved, starting aggregation, aggregation complete, number of years aggregated, starting upload to httpbin, upload outcome.\n",
    "4.\tExecution Time Measurement:\n",
    "o\tCode Execution Time: Measure the time taken to perform the main operations (data retrieval + aggregation). Print this time after the aggregation operation is complete.\n",
    "o\tPipeline Execution Time: Measure the total execution time of the entire script (from the beginning until after the upload to httpbin). Print this total time at the end of the script. Use Python's time module.\n",
    "5.\tUpload Result:\n",
    "o\tTake the resulting aggregated summary dictionary (year counts) from the aggregate operation.\n",
    "o\tSerialize it into JSON format.\n",
    "o\tMake an HTTP POST request to the https://httpbin.org/post endpoint, sending the resulting aggregated JSON data in the request body.\n",
    "o\tVerify the response from httpbin.org (e.g., check the status code) and log the outcome of the upload operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acadff3a-4609-4a37-a316-cd5989c71be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define control parameters\n",
    "API_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "HTTPBIN_POST_URL = \"https://httpbin.org/post\"\n",
    "\n",
    "def retrieve_launch_data(api_url):\n",
    "    \"\"\"\n",
    "    Retrieve launch data from the SpaceX API.\n",
    "    Handles potential errors such as timeouts or non-200 status codes.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Starting data retrieval from {api_url}\")\n",
    "        response = requests.get(api_url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        data = response.json()\n",
    "        logging.info(f\"Data retrieval successful. Retrieved {len(data)} launches.\")\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error during data retrieval: {e}\")\n",
    "        return None\n",
    "\n",
    "def aggregate_launch_data(launch_data):\n",
    "    \"\"\"\n",
    "    Aggregate the launch data by year.\n",
    "    Returns a dictionary with years as keys and the count of launches as values.\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting aggregation of launch data.\")\n",
    "    year_counts = {}\n",
    "    for launch in launch_data:\n",
    "        launch_year = launch['launch_year']\n",
    "        if launch_year in year_counts:\n",
    "            year_counts[launch_year] += 1\n",
    "        else:\n",
    "            year_counts[launch_year] = 1\n",
    "    logging.info(f\"Aggregation complete. Aggregated {len(year_counts)} years.\")\n",
    "    return year_counts\n",
    "\n",
    "def upload_to_httpbin(data, post_url):\n",
    "    \"\"\"\n",
    "    Serialize the aggregated data into JSON and upload it to httpbin.org.\n",
    "    Logs the outcome of the upload operation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(f\"Starting upload to {post_url}\")\n",
    "        json_data = json.dumps(data)\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        response = requests.post(post_url, data=json_data, headers=headers, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        logging.info(f\"Upload successful. Status code: {response.status_code}\")\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error during upload to httpbin: {e}\")\n",
    "        return False\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    start_time_pipeline = time.time()\n",
    "\n",
    "    # Step 1: Retrieve launch data\n",
    "    launch_data = retrieve_launch_data(API_ENDPOINT_URL)\n",
    "    if launch_data is None:\n",
    "        logging.error(\"Failed to retrieve launch data. Exiting script.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Measure time for data retrieval + aggregation\n",
    "    start_time_main_operations = time.time()\n",
    "\n",
    "    # Step 2: Aggregate launch data\n",
    "    year_counts = aggregate_launch_data(launch_data)\n",
    "    for year, count in sorted(year_counts.items()):\n",
    "        print(f\"Year: {year}, Total Launches: {count}\")\n",
    "\n",
    "    # Measure and log execution time for main operations\n",
    "    main_operations_time = time.time() - start_time_main_operations\n",
    "    logging.info(f\"Time taken for data retrieval and aggregation: {main_operations_time:.2f} seconds\")\n",
    "\n",
    "    # Step 3: Upload aggregated data to httpbin\n",
    "    upload_successful = upload_to_httpbin(year_counts, HTTPBIN_POST_URL)\n",
    "\n",
    "    # Measure and log total pipeline execution time\n",
    "    total_pipeline_time = time.time() - start_time_pipeline\n",
    "    logging.info(f\"Total pipeline execution time: {total_pipeline_time:.2f} seconds\")\n",
    "\n",
    "    if not upload_successful:\n",
    "        logging.error(\"Pipeline completed with errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c62f090e-3280-4ae8-b6a0-f0323975b8c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "QWEN 2.5-MAX",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
