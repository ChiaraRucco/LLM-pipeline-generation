{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6013620-52de-4e21-aa7c-ea5c0d9a24a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are an expert Python developer specializing in the Databricks environment. Your task is to create a complete Python script to be executed within a Databricks notebook. The script must perform the following operations:\n",
    "1.\tData Retrieval from SpaceX API:\n",
    "o\tInteract with the SpaceX v3 REST API (https://api.spacexdata.com/v3).\n",
    "o\tRetrieve data from one specific endpoint: \n",
    "\tAll launches: https://api.spacexdata.com/v3/launches\n",
    "o\tHandle potential errors during the API calls (e.g., timeouts, non-200 status codes).\n",
    "2.\tAggregate Operation:\n",
    "o\tPerform a simple \"aggregate\" operation on the retrieved launch data.\n",
    "o\tAggregation Logic: Calculate the total number of launches for each year.\n",
    "o\tReturn a print with the number of aggregate launches for each year\n",
    "3.\tControl Parameters and Debugging:\n",
    "o\tInclude a variable at the beginning of the script to define the API endpoint URL, making it easily modifiable: \n",
    "\tAPI_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "o\tUse Python's standard logging module to provide informative output during execution. Configure logging to display messages at the INFO level.\n",
    "o\tLog key messages such as: starting data retrieval, number of launches retrieved, starting aggregation, aggregation complete, number of years aggregated, starting upload to httpbin, upload outcome.\n",
    "4.\tExecution Time Measurement:\n",
    "o\tCode Execution Time: Measure the time taken to perform the main operations (data retrieval + aggregation). Print this time after the aggregation operation is complete.\n",
    "o\tPipeline Execution Time: Measure the total execution time of the entire script (from the beginning until after the upload to httpbin). Print this total time at the end of the script. Use Python's time module.\n",
    "5.\tUpload Result:\n",
    "o\tTake the resulting aggregated summary dictionary (year counts) from the aggregate operation.\n",
    "o\tSerialize it into JSON format.\n",
    "o\tMake an HTTP POST request to the https://httpbin.org/post endpoint, sending the resulting aggregated JSON data in the request body.\n",
    "o\tVerify the response from httpbin.org (e.g., check the status code) and log the outcome of the upload operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acadff3a-4609-4a37-a316-cd5989c71be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the API endpoint URL\n",
    "API_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def retrieve_launch_data():\n",
    "    \"\"\"Retrieve launch data from the SpaceX API.\"\"\"\n",
    "    try:\n",
    "        logging.info(\"Starting data retrieval...\")\n",
    "        response = requests.get(API_ENDPOINT_URL, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        launch_data = response.json()\n",
    "        logging.info(f\"Number of launches retrieved: {len(launch_data)}\")\n",
    "        return launch_data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error retrieving data: {e}\")\n",
    "        return None\n",
    "\n",
    "def aggregate_launch_data(launch_data):\n",
    "    \"\"\"Aggregate launch data by year.\"\"\"\n",
    "    if launch_data is None:\n",
    "        return None\n",
    "    try:\n",
    "        logging.info(\"Starting aggregation...\")\n",
    "        aggregated_data = {}\n",
    "        for launch in launch_data:\n",
    "            launch_year = datetime.strptime(launch['launch_date_utc'], '%Y-%m-%dT%H:%M:%S.%fZ').year\n",
    "            if launch_year in aggregated_data:\n",
    "                aggregated_data[launch_year] += 1\n",
    "            else:\n",
    "                aggregated_data[launch_year] = 1\n",
    "        logging.info(f\"Aggregation complete. Number of years aggregated: {len(aggregated_data)}\")\n",
    "        return aggregated_data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error aggregating data: {e}\")\n",
    "        return None\n",
    "\n",
    "def upload_aggregated_data(aggregated_data):\n",
    "    \"\"\"Upload aggregated data to httpbin.org.\"\"\"\n",
    "    if aggregated_data is None:\n",
    "        return\n",
    "    try:\n",
    "        logging.info(\"Starting upload to httpbin...\")\n",
    "        json_data = json.dumps(aggregated_data)\n",
    "        response = requests.post('https://httpbin.org/post', data=json_data)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        logging.info(f\"Upload outcome: {response.json()['data']}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error uploading data: {e}\")\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    launch_data = retrieve_launch_data()\n",
    "    aggregated_data = aggregate_launch_data(launch_data)\n",
    "    if aggregated_data is not None:\n",
    "        print(\"Number of aggregate launches for each year:\")\n",
    "        for year, count in aggregated_data.items():\n",
    "            print(f\"{year}: {count}\")\n",
    "    code_execution_time = time.time() - start_time\n",
    "    logging.info(f\"Code execution time: {code_execution_time:.2f} seconds\")\n",
    "    upload_aggregated_data(aggregated_data)\n",
    "    total_execution_time = time.time() - start_time\n",
    "    logging.info(f\"Total execution time: {total_execution_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cae21227-82c2-4c10-aad4-5bff040bbf82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LLAMA 3.3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
