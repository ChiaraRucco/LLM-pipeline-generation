{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6013620-52de-4e21-aa7c-ea5c0d9a24a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are an expert Python developer specializing in the Databricks environment. Your task is to create a complete Python script to be executed within a Databricks notebook. The script must perform the following operations:\n",
    "1.\tData Retrieval from SpaceX API:\n",
    "o\tInteract with the SpaceX v3 REST API (https://api.spacexdata.com/v3).\n",
    "o\tRetrieve data from two specific endpoints: \n",
    "\tAll launches: https://api.spacexdata.com/v3/launches\n",
    "\tAll rockets: https://api.spacexdata.com/v3/rockets\n",
    "o\tHandle potential errors during the API calls (e.g., timeouts, non-200 status codes).\n",
    "2.\tMerge Operation:\n",
    "o\tPerform a \"merge\" (or join) operation between the launches data and the rockets data.\n",
    "o\tMerge Logic: For each launch record, add the rocket's name (rocket_name) from the rockets dataset. The match should be based on the rocket.rocket_id field present in each launch record corresponding to the rocket_id field in each rocket record.\n",
    "o\tThe final result should be a list of dictionaries, where each dictionary represents a launch enriched with its corresponding rocket name.\n",
    "3.\tControl Parameters and Debugging:\n",
    "o\tInclude variables at the beginning of the script to define the API endpoint URLs, making them easily modifiable.\n",
    "o\tUse Python's standard logging module to provide informative output during execution. Configure logging to display messages at the INFO level.\n",
    "o\tLog key messages such as: starting data retrieval, number of launches retrieved, number of rockets retrieved, starting merge operation, number of records after merge, starting upload to httpbin, upload outcome.\n",
    "4.\tExecution Time Measurement:\n",
    "o\tCode Execution Time: Measure the time taken to perform the main operations (data retrieval + merge). Print this time after the merge operation is complete.\n",
    "o\tPipeline Execution Time: Measure the total execution time of the entire script (from the beginning until after the upload to httpbin). Print this total time at the end of the script. Use Python's time module.\n",
    "5.\tUpload Result:\n",
    "o\tTake the resulting list from the merge operation.\n",
    "o\tSerialize it into JSON format.\n",
    "o\tMake an HTTP POST request to the https://httpbin.org/post endpoint, sending the resulting JSON data in the request body.\n",
    "o\tVerify the response from httpbin.org (e.g., check the status code) and log the outcome of the upload operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acadff3a-4609-4a37-a316-cd5989c71be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks SpaceX ETL Pipeline\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Control Parameters\n",
    "LAUNCHES_API_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "ROCKETS_API_URL = \"https://api.spacexdata.com/v3/rockets\"\n",
    "HTTPBIN_POST_URL = \"https://httpbin.org/post\"\n",
    "REQUEST_TIMEOUT = 30  # seconds\n",
    "\n",
    "def fetch_api_data(url, timeout=REQUEST_TIMEOUT):\n",
    "    \"\"\"\n",
    "    Fetch data from a REST API endpoint with error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Fetching data from {url}\")\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        response.raise_for_status()  # Raise an exception for non-200 status codes\n",
    "        return response.json()\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Timeout error when fetching data from {url}\")\n",
    "        raise\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err}\")\n",
    "        raise\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        logger.error(f\"Request error occurred: {req_err}\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as json_err:\n",
    "        logger.error(f\"JSON decode error: {json_err}\")\n",
    "        raise\n",
    "\n",
    "def merge_launches_with_rockets(launches, rockets):\n",
    "    \"\"\"\n",
    "    Merge launches data with rockets data based on rocket_id\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting merge operation between launches and rockets\")\n",
    "    \n",
    "    # Create a dictionary of rockets with rocket_id as key for faster lookups\n",
    "    rockets_dict = {rocket[\"rocket_id\"]: rocket for rocket in rockets}\n",
    "    \n",
    "    # Merge the data\n",
    "    merged_launches = []\n",
    "    for launch in launches:\n",
    "        launch_data = launch.copy()  # Create a copy to avoid modifying the original\n",
    "        rocket_id = launch.get(\"rocket\", {}).get(\"rocket_id\")\n",
    "        \n",
    "        if rocket_id and rocket_id in rockets_dict:\n",
    "            launch_data[\"rocket_name\"] = rockets_dict[rocket_id][\"rocket_name\"]\n",
    "        else:\n",
    "            launch_data[\"rocket_name\"] = \"Unknown\"\n",
    "            \n",
    "        merged_launches.append(launch_data)\n",
    "    \n",
    "    logger.info(f\"Merge completed. Total records after merge: {len(merged_launches)}\")\n",
    "    return merged_launches\n",
    "\n",
    "def upload_to_httpbin(data):\n",
    "    \"\"\"\n",
    "    Upload data to httpbin.org/post and verify the response\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting upload to {HTTPBIN_POST_URL}\")\n",
    "    try:\n",
    "        # Convert data to JSON\n",
    "        json_data = json.dumps(data)\n",
    "        \n",
    "        # Upload to httpbin\n",
    "        response = requests.post(HTTPBIN_POST_URL, data=json_data, \n",
    "                                headers={\"Content-Type\": \"application/json\"},\n",
    "                                timeout=REQUEST_TIMEOUT)\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Verify response\n",
    "        response_data = response.json()\n",
    "        if response_data and \"data\" in response_data:\n",
    "            logger.info(\"Upload successful\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.warning(\"Upload completed but response verification failed\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error uploading data to httpbin: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the ETL pipeline\n",
    "    \"\"\"\n",
    "    # Start timing the entire pipeline\n",
    "    pipeline_start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Start timing the data retrieval and merge operations\n",
    "        operation_start_time = time.time()\n",
    "        \n",
    "        # Fetch data from SpaceX API\n",
    "        launches = fetch_api_data(LAUNCHES_API_URL)\n",
    "        logger.info(f\"Retrieved {len(launches)} launches\")\n",
    "        \n",
    "        rockets = fetch_api_data(ROCKETS_API_URL)\n",
    "        logger.info(f\"Retrieved {len(rockets)} rockets\")\n",
    "        \n",
    "        # Merge data\n",
    "        merged_data = merge_launches_with_rockets(launches, rockets)\n",
    "        \n",
    "        # Calculate and log the operation execution time\n",
    "        operation_duration = time.time() - operation_start_time\n",
    "        logger.info(f\"Data retrieval and merge operations completed in {operation_duration:.2f} seconds\")\n",
    "        \n",
    "        # Upload result to httpbin\n",
    "        upload_success = upload_to_httpbin(merged_data)\n",
    "        upload_status = \"Success\" if upload_success else \"Failed\"\n",
    "        logger.info(f\"Data upload status: {upload_status}\")\n",
    "        \n",
    "        # Calculate and log the total pipeline execution time\n",
    "        pipeline_duration = time.time() - pipeline_start_time\n",
    "        logger.info(f\"Total pipeline execution time: {pipeline_duration:.2f} seconds\")\n",
    "        \n",
    "        # Display execution times in a formatted way\n",
    "        print(\"\\n--- Execution Time Summary ---\")\n",
    "        print(f\"Data Retrieval + Merge: {operation_duration:.2f} seconds\")\n",
    "        print(f\"Total Pipeline Execution: {pipeline_duration:.2f} seconds\")\n",
    "        print(f\"Upload Status: {upload_status}\")\n",
    "        print(f\"Total Records Processed: {len(merged_data)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline execution failed: {str(e)}\")\n",
    "        # Calculate execution time even if there was an error\n",
    "        pipeline_duration = time.time() - pipeline_start_time\n",
    "        logger.info(f\"Pipeline terminated after {pipeline_duration:.2f} seconds due to an error\")\n",
    "\n",
    "# Entry point for Databricks notebook execution\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting SpaceX ETL pipeline\")\n",
    "    main()\n",
    "    logger.info(\"Pipeline execution completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cd61cbe-c2c1-4973-84e9-6e0224f7c03e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CLAUDE 3.7 SONNET",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
