{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6013620-52de-4e21-aa7c-ea5c0d9a24a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are an expert Python developer specializing in the Databricks environment. Your task is to create a complete Python script to be executed within a Databricks notebook. The script must perform the following operations:\n",
    "1.\tData Retrieval from SpaceX API:\n",
    "o\tInteract with the SpaceX v3 REST API (https://api.spacexdata.com/v3).\n",
    "o\tRetrieve data from one specific endpoint: \n",
    "\tAll launches: https://api.spacexdata.com/v3/launches\n",
    "o\tHandle potential errors during the API calls (e.g., timeouts, non-200 status codes).\n",
    "2.\tFilter Operation:\n",
    "o\tPerform a \"filter\" operation on the retrieved launch data based on specific criteria.\n",
    "o\tFilter Logic: Filter the list of launches based on launch year and launch success status. Only include launches that match the specified criteria.\n",
    "o\tThe result should be a list of dictionaries, containing only the launch records that satisfy the filter conditions.\n",
    "3.\tControl Parameters and Debugging:\n",
    "o\tInclude variables at the beginning of the script to define the API endpoint URL and the filtering criteria, making them easily modifiable. Use parameters like: \n",
    "\tAPI_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "\tFILTER_YEAR = 2019 (Set to an integer year, or None to disable year filtering)\n",
    "\tFILTER_SUCCESS = True (Set to True, False, or None to disable success filtering)\n",
    "o\tUse Python's standard logging module to provide informative output during execution. Configure logging to display messages at the INFO level.\n",
    "o\tLog key messages such as: starting data retrieval, number of launches retrieved, filtering criteria being applied, number of launches before filtering, number of launches after filtering, starting upload to httpbin, upload outcome.\n",
    "4.\tExecution Time Measurement:\n",
    "o\tCode Execution Time: Measure the time taken to perform the main operations (data retrieval + filtering). Print this time after the filtering operation is complete.\n",
    "o\tPipeline Execution Time: Measure the total execution time of the entire script (from the beginning until after the upload to httpbin). Print this total time at the end of the script. Use Python's time module.\n",
    "5.\tUpload Result:\n",
    "o\tTake the resulting filtered list from the filter operation.\n",
    "o\tSerialize it into JSON format.\n",
    "o\tMake an HTTP POST request to the https://httpbin.org/post endpoint, sending the resulting filtered JSON data in the request body.\n",
    "o\tVerify the response from httpbin.org (e.g., check the status code) and log the outcome of the upload operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acadff3a-4609-4a37-a316-cd5989c71be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Control Parameters\n",
    "API_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "FILTER_YEAR = 2019  # Set to an integer year, or None to disable year filtering\n",
    "FILTER_SUCCESS = True  # Set to True, False, or None to disable success filtering\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Measure total pipeline execution time\n",
    "pipeline_start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Log start of data retrieval\n",
    "    logging.info(\"Starting data retrieval from SpaceX API...\")\n",
    "    retrieval_start_time = time.time()\n",
    "\n",
    "    # Make API call to retrieve launch data\n",
    "    try:\n",
    "        response = requests.get(API_ENDPOINT_URL, timeout=10)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        launches = response.json()\n",
    "        logging.info(f\"Data retrieval successful. Retrieved {len(launches)} launches.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error during API call: {e}\")\n",
    "        raise\n",
    "\n",
    "    retrieval_end_time = time.time()\n",
    "    logging.info(f\"Data retrieval completed in {retrieval_end_time - retrieval_start_time:.2f} seconds.\")\n",
    "\n",
    "    # Filter operation\n",
    "    logging.info(\"Starting filtering operation...\")\n",
    "    filter_start_time = time.time()\n",
    "\n",
    "    # Apply filtering criteria\n",
    "    filtered_launches = []\n",
    "    for launch in launches:\n",
    "        include_launch = True\n",
    "\n",
    "        # Apply year filter if FILTER_YEAR is set\n",
    "        if FILTER_YEAR is not None and launch.get(\"launch_year\") != str(FILTER_YEAR):\n",
    "            include_launch = False\n",
    "\n",
    "        # Apply success filter if FILTER_SUCCESS is set\n",
    "        if FILTER_SUCCESS is not None and launch.get(\"launch_success\") != FILTER_SUCCESS:\n",
    "            include_launch = False\n",
    "\n",
    "        if include_launch:\n",
    "            filtered_launches.append(launch)\n",
    "\n",
    "    filter_end_time = time.time()\n",
    "    logging.info(f\"Filtering completed in {filter_end_time - filter_start_time:.2f} seconds.\")\n",
    "    logging.info(f\"Number of launches before filtering: {len(launches)}\")\n",
    "    logging.info(f\"Number of launches after filtering: {len(filtered_launches)}\")\n",
    "\n",
    "    # Serialize filtered data to JSON\n",
    "    filtered_data_json = json.dumps(filtered_launches)\n",
    "\n",
    "    # Upload result to httpbin.org\n",
    "    logging.info(\"Starting upload to httpbin.org...\")\n",
    "    upload_start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        upload_response = requests.post(\"https://httpbin.org/post\", data=filtered_data_json, timeout=10)\n",
    "        upload_response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        logging.info(f\"Upload successful. Response status code: {upload_response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error during upload to httpbin.org: {e}\")\n",
    "        raise\n",
    "\n",
    "    upload_end_time = time.time()\n",
    "    logging.info(f\"Upload completed in {upload_end_time - upload_start_time:.2f} seconds.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during execution: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Measure total pipeline execution time\n",
    "    pipeline_end_time = time.time()\n",
    "    logging.info(f\"Total pipeline execution time: {pipeline_end_time - pipeline_start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c62f090e-3280-4ae8-b6a0-f0323975b8c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "QWEN 2.5-MAX",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
