{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6013620-52de-4e21-aa7c-ea5c0d9a24a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are an expert Python developer specializing in the Databricks environment. Your task is to create a complete Python script to be executed within a Databricks notebook. The script must perform the following operations:\n",
    "1.\tData Retrieval from SpaceX API:\n",
    "o\tInteract with the SpaceX v3 REST API (https://api.spacexdata.com/v3).\n",
    "o\tRetrieve data from two specific endpoints: \n",
    "\tAll launches: https://api.spacexdata.com/v3/launches\n",
    "\tAll rockets: https://api.spacexdata.com/v3/rockets\n",
    "o\tHandle potential errors during the API calls (e.g., timeouts, non-200 status codes).\n",
    "2.\tJOIN Operation:\n",
    "o\tPerform a \"JOIN\" operation to combine information from the launches data and the rockets data.\n",
    "o\tJoin Logic: For each launch record, look up the corresponding rocket record using the rocket identifier. The join key is the rocket.rocket_id field within each launch record, which matches the rocket_id field in the rocket records. Add the rocket_name from the matched rocket record to the launch record. (This is conceptually similar to a left join, keeping all launch records).\n",
    "o\tThe final result should be a list of dictionaries, where each dictionary represents a launch enriched with the corresponding rocket_name.\n",
    "3.\tControl Parameters and Debugging:\n",
    "o\tInclude variables at the beginning of the script to define the API endpoint URLs, making them easily modifiable: \n",
    "\tLAUNCHES_API_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "\tROCKETS_API_URL = \"https://api.spacexdata.com/v3/rockets\"\n",
    "o\tUse Python's standard logging module to provide informative output during execution. Configure logging to display messages at the INFO level.\n",
    "o\tLog key messages such as: starting data retrieval (for launches, for rockets), number of launches retrieved, number of rockets retrieved, starting join operation, join operation complete, number of records after join, starting upload to httpbin, upload outcome.\n",
    "4.\tExecution Time Measurement:\n",
    "o\tCode Execution Time: Measure the time taken to perform the main operations (data retrieval + join operation). Print this time after the join operation is complete.\n",
    "o\tPipeline Execution Time: Measure the total execution time of the entire script (from the beginning until after the upload to httpbin). Print this total time at the end of the script. Use Python's time module.\n",
    "5.\tUpload Result:\n",
    "o\tTake the resulting joined list of dictionaries from the join operation.\n",
    "o\tSerialize it into JSON format.\n",
    "o\tMake an HTTP POST request to the https://httpbin.org/post endpoint, sending the resulting joined JSON data in the request body.\n",
    "o\tVerify the response from httpbin.org (e.g., check the status code) and log the outcome of the upload operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acadff3a-4609-4a37-a316-cd5989c71be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SpaceX API Data Processing Script for Databricks\n",
    "# This script retrieves data from SpaceX API, performs a join operation,\n",
    "# and uploads the results to httpbin.org\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# API endpoint URLs\n",
    "LAUNCHES_API_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "ROCKETS_API_URL = \"https://api.spacexdata.com/v3/rockets\"\n",
    "UPLOAD_URL = \"https://httpbin.org/post\"\n",
    "\n",
    "# Timeout settings for API requests (in seconds)\n",
    "REQUEST_TIMEOUT = 30\n",
    "\n",
    "def get_data_from_api(url, endpoint_name):\n",
    "    \"\"\"\n",
    "    Retrieve data from the specified API endpoint\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting data retrieval from {endpoint_name} API\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=REQUEST_TIMEOUT)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            logger.info(f\"Successfully retrieved {len(data)} records from {endpoint_name} API\")\n",
    "            return data\n",
    "        else:\n",
    "            logger.error(f\"Failed to retrieve data from {endpoint_name} API. Status code: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Request to {endpoint_name} API timed out after {REQUEST_TIMEOUT} seconds\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error retrieving data from {endpoint_name} API: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def join_launches_with_rockets(launches, rockets):\n",
    "    \"\"\"\n",
    "    Join launches data with rockets data based on rocket_id\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting join operation between launches and rockets data\")\n",
    "    \n",
    "    # Create a dictionary of rockets for faster lookup\n",
    "    rockets_dict = {rocket['rocket_id']: rocket for rocket in rockets}\n",
    "    \n",
    "    # Perform the join operation\n",
    "    joined_data = []\n",
    "    for launch in launches:\n",
    "        # Create a copy of the launch record\n",
    "        enriched_launch = launch.copy()\n",
    "        \n",
    "        # Get the rocket_id from the launch record\n",
    "        rocket_id = launch.get('rocket', {}).get('rocket_id')\n",
    "        \n",
    "        # Look up the corresponding rocket record and add rocket_name to the launch record\n",
    "        if rocket_id and rocket_id in rockets_dict:\n",
    "            enriched_launch['rocket']['rocket_name'] = rockets_dict[rocket_id]['rocket_name']\n",
    "        else:\n",
    "            enriched_launch['rocket']['rocket_name'] = \"Unknown\"\n",
    "            \n",
    "        joined_data.append(enriched_launch)\n",
    "    \n",
    "    logger.info(f\"Join operation complete. Result contains {len(joined_data)} records\")\n",
    "    return joined_data\n",
    "\n",
    "def upload_data_to_httpbin(data):\n",
    "    \"\"\"\n",
    "    Upload the joined data to httpbin.org\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting upload to httpbin.org\")\n",
    "    \n",
    "    try:\n",
    "        # Serialize the data to JSON\n",
    "        json_data = json.dumps(data)\n",
    "        \n",
    "        # Send the data to httpbin.org\n",
    "        response = requests.post(\n",
    "            UPLOAD_URL,\n",
    "            data=json_data,\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            timeout=REQUEST_TIMEOUT\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            logger.info(\"Successfully uploaded data to httpbin.org\")\n",
    "            return True\n",
    "        else:\n",
    "            logger.error(f\"Failed to upload data to httpbin.org. Status code: {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Upload to httpbin.org timed out after {REQUEST_TIMEOUT} seconds\")\n",
    "        return False\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error uploading data to httpbin.org: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the entire process\n",
    "    \"\"\"\n",
    "    # Start measuring total pipeline execution time\n",
    "    pipeline_start_time = time.time()\n",
    "    \n",
    "    # Retrieve data from APIs\n",
    "    operation_start_time = time.time()\n",
    "    launches_data = get_data_from_api(LAUNCHES_API_URL, \"launches\")\n",
    "    rockets_data = get_data_from_api(ROCKETS_API_URL, \"rockets\")\n",
    "    \n",
    "    # Check if data retrieval was successful\n",
    "    if not launches_data or not rockets_data:\n",
    "        logger.error(\"Failed to retrieve required data. Exiting script.\")\n",
    "        return\n",
    "    \n",
    "    # Perform the join operation\n",
    "    joined_data = join_launches_with_rockets(launches_data, rockets_data)\n",
    "    \n",
    "    # Calculate and log the execution time for data retrieval and join operation\n",
    "    operation_execution_time = time.time() - operation_start_time\n",
    "    logger.info(f\"Data retrieval and join operation completed in {operation_execution_time:.2f} seconds\")\n",
    "    \n",
    "    # Upload the joined data to httpbin.org\n",
    "    upload_success = upload_data_to_httpbin(joined_data)\n",
    "    \n",
    "    # Calculate and log the total pipeline execution time\n",
    "    pipeline_execution_time = time.time() - pipeline_start_time\n",
    "    logger.info(f\"Total pipeline execution time: {pipeline_execution_time:.2f} seconds\")\n",
    "    \n",
    "    # Return the status for Databricks notebook execution\n",
    "    return {\n",
    "        \"status\": \"success\" if upload_success else \"failure\",\n",
    "        \"records_processed\": len(joined_data),\n",
    "        \"operation_execution_time\": operation_execution_time,\n",
    "        \"pipeline_execution_time\": pipeline_execution_time\n",
    "    }\n",
    "\n",
    "# Execute the script\n",
    "if __name__ == \"__main__\":\n",
    "    result = main()\n",
    "    print(f\"Script execution completed with result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6c2d32e-121d-424b-ab13-45e41c13e8b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CLAUDE 3.7 SONNET",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
