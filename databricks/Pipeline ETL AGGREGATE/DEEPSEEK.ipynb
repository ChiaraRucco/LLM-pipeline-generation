{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6013620-52de-4e21-aa7c-ea5c0d9a24a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "You are an expert Python developer specializing in the Databricks environment. Your task is to create a complete Python script to be executed within a Databricks notebook. The script must perform the following operations:\n",
    "1.\tData Retrieval from SpaceX API:\n",
    "o\tInteract with the SpaceX v3 REST API (https://api.spacexdata.com/v3).\n",
    "o\tRetrieve data from one specific endpoint: \n",
    "\tAll launches: https://api.spacexdata.com/v3/launches\n",
    "o\tHandle potential errors during the API calls (e.g., timeouts, non-200 status codes).\n",
    "2.\tAggregate Operation:\n",
    "o\tPerform a simple \"aggregate\" operation on the retrieved launch data.\n",
    "o\tAggregation Logic: Calculate the total number of launches for each year.\n",
    "o\tReturn a print with the number of aggregate launches for each year\n",
    "3.\tControl Parameters and Debugging:\n",
    "o\tInclude a variable at the beginning of the script to define the API endpoint URL, making it easily modifiable: \n",
    "\tAPI_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "o\tUse Python's standard logging module to provide informative output during execution. Configure logging to display messages at the INFO level.\n",
    "o\tLog key messages such as: starting data retrieval, number of launches retrieved, starting aggregation, aggregation complete, number of years aggregated, starting upload to httpbin, upload outcome.\n",
    "4.\tExecution Time Measurement:\n",
    "o\tCode Execution Time: Measure the time taken to perform the main operations (data retrieval + aggregation). Print this time after the aggregation operation is complete.\n",
    "o\tPipeline Execution Time: Measure the total execution time of the entire script (from the beginning until after the upload to httpbin). Print this total time at the end of the script. Use Python's time module.\n",
    "5.\tUpload Result:\n",
    "o\tTake the resulting aggregated summary dictionary (year counts) from the aggregate operation.\n",
    "o\tSerialize it into JSON format.\n",
    "o\tMake an HTTP POST request to the https://httpbin.org/post endpoint, sending the resulting aggregated JSON data in the request body.\n",
    "o\tVerify the response from httpbin.org (e.g., check the status code) and log the outcome of the upload operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acadff3a-4609-4a37-a316-cd5989c71be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "API_ENDPOINT_URL = \"https://api.spacexdata.com/v3/launches\"\n",
    "HTTPBIN_POST_URL = \"https://httpbin.org/post\"\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def retrieve_launch_data():\n",
    "    \"\"\"Retrieve launch data from SpaceX API\"\"\"\n",
    "    logger.info(\"Starting data retrieval from SpaceX API\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(API_ENDPOINT_URL, timeout=10)\n",
    "        response.raise_for_status()  # Raises exception for 4XX/5XX status codes\n",
    "        \n",
    "        launches = response.json()\n",
    "        logger.info(f\"Successfully retrieved {len(launches)} launches\")\n",
    "        return launches\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Failed to retrieve launch data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def aggregate_launches_by_year(launches):\n",
    "    \"\"\"Aggregate launches by year\"\"\"\n",
    "    logger.info(\"Starting aggregation of launches by year\")\n",
    "    \n",
    "    year_counts = {}\n",
    "    \n",
    "    for launch in launches:\n",
    "        try:\n",
    "            # Extract year from launch date (UTC)\n",
    "            launch_date = launch['launch_date_utc']\n",
    "            year = datetime.strptime(launch_date, '%Y-%m-%dT%H:%M:%S.%fZ').year\n",
    "            \n",
    "            # Increment count for this year\n",
    "            year_counts[year] = year_counts.get(year, 0) + 1\n",
    "            \n",
    "        except (KeyError, ValueError) as e:\n",
    "            logger.warning(f\"Skipping launch with invalid date format: {launch.get('flight_number', 'unknown')}\")\n",
    "    \n",
    "    logger.info(f\"Aggregation complete. Found {len(year_counts)} distinct years\")\n",
    "    return year_counts\n",
    "\n",
    "def upload_results(data):\n",
    "    \"\"\"Upload aggregated data to httpbin\"\"\"\n",
    "    logger.info(\"Starting upload to httpbin\")\n",
    "    \n",
    "    try:\n",
    "        # Serialize data to JSON\n",
    "        json_data = json.dumps(data)\n",
    "        \n",
    "        # Make POST request\n",
    "        response = requests.post(\n",
    "            HTTPBIN_POST_URL,\n",
    "            data=json_data,\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            timeout=10\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        logger.info(\"Upload to httpbin successful\")\n",
    "        return True\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Failed to upload to httpbin: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution pipeline\"\"\"\n",
    "    # Start timer for total execution time\n",
    "    pipeline_start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Measure data retrieval and aggregation time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Retrieve launch data\n",
    "        launches = retrieve_launch_data()\n",
    "        \n",
    "        # Step 2: Aggregate launches by year\n",
    "        year_counts = aggregate_launches_by_year(launches)\n",
    "        \n",
    "        # Print the aggregated results\n",
    "        print(\"\\nNumber of launches by year:\")\n",
    "        for year, count in sorted(year_counts.items()):\n",
    "            print(f\"{year}: {count} launches\")\n",
    "        \n",
    "        # Log execution time for data retrieval + aggregation\n",
    "        execution_time = time.time() - start_time\n",
    "        print(f\"\\nData retrieval and aggregation completed in {execution_time:.2f} seconds\")\n",
    "        \n",
    "        # Step 3: Upload results\n",
    "        upload_success = upload_results(year_counts)\n",
    "        \n",
    "        # Log total pipeline execution time\n",
    "        total_time = time.time() - pipeline_start_time\n",
    "        print(f\"\\nTotal pipeline execution time: {total_time:.2f} seconds\")\n",
    "        \n",
    "        return year_counts\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67d5bbf0-6522-42dd-9e9c-71749a24e9be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DEEPSEEK",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
